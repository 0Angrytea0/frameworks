{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "zGMuCQ_zdrsi"
      },
      "outputs": [],
      "source": [
        "#KGAT_746a8c48819a19cbaf8ca0048244831b"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opendatasets\n",
        "!pip install pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5CT29pFgC0a",
        "outputId": "54588b7e-1049-40dd-b5e5-4ea202eaec74"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opendatasets in /usr/local/lib/python3.12/dist-packages (0.1.22)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from opendatasets) (4.67.1)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (from opendatasets) (1.7.4.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from opendatasets) (8.3.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (6.3.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2025.11.12)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (3.4.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (3.11)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (0.5.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Библиотеки"
      ],
      "metadata": {
        "id": "x5q2Fut1gNrj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LinearRegression, Ridge\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.base import BaseEstimator, RegressorMixin"
      ],
      "metadata": {
        "id": "58AiRGMTgD5t"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Скачиваем датасет"
      ],
      "metadata": {
        "id": "Uoy5qz0cgPrh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "od.download(\"https://www.kaggle.com/datasets/kirbysasuke/house-price-prediction-simplified-for-regression\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOVC8PSkgHG5",
        "outputId": "a75f1b17-b6b7-4657-8310-fe53d4230686"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping, found downloaded files in \"./house-price-prediction-simplified-for-regression\" (use force=True to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Чтение датасета"
      ],
      "metadata": {
        "id": "a1GqNNgbiL9H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option(\"display.max_columns\", None)\n",
        "df = pd.read_csv(\"house-price-prediction-simplified-for-regression/Real_Estate.csv\")"
      ],
      "metadata": {
        "id": "YmPEzGF6iOKg"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Приводим таргет к числовому типу, удаляя строки, которые не удалось конвертировать  \n",
        "В House price of unit area есть цена 0, что может помешать модели, поэтому удаляем  "
      ],
      "metadata": {
        "id": "f-rZRwv5gbW_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"House price of unit area\"] = pd.to_numeric(df[\"House price of unit area\"], errors=\"coerce\")\n",
        "df = df.dropna(subset=[\"House price of unit area\"])\n",
        "\n",
        "df = df[df[\"House price of unit area\"] > 0].copy()"
      ],
      "metadata": {
        "id": "17tqwxcOgVNO"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Формируем признаки и целевую переменную\n",
        "Таргет - цена\n",
        "Признаки использую все, кроме цены и времени, осталяя только числовые характеристики  \n",
        "Делюсь на обучающую и тестовую выборки. В бейзлайне использую линейную регрессию из sklearn с предварительным стандартизированием всех признаков. Считаю три метрики: MAE, RMSE и R^2, чтобы оценить базовое качество линейной модели на исходных признаках"
      ],
      "metadata": {
        "id": "SFGcgiafhJFJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MAE ≈ 9.65 показывает, что средняя ошибка прогноза по цене довольно велика относительно типичных значений. RMSE ≈ 11.37 указывает на наличие отдельных более крупных промахов. R^2 ≈ 0.28 означает, что модель объясняет только ~28% разброса цен"
      ],
      "metadata": {
        "id": "2EUQ48PVktbW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = df[\"House price of unit area\"]\n",
        "X = df.drop(columns=[\"House price of unit area\", \"Transaction date\"])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "num_cols = X.columns.tolist()\n",
        "\n",
        "preprocessor_reg = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", StandardScaler(), num_cols),\n",
        "    ]\n",
        ")\n",
        "\n",
        "lin_reg_baseline = Pipeline(steps=[\n",
        "    (\"preprocess\", preprocessor_reg),\n",
        "    (\"model\", LinearRegression())\n",
        "])\n",
        "\n",
        "lin_reg_baseline.fit(X_train, y_train)\n",
        "y_pred_base = lin_reg_baseline.predict(X_test)\n",
        "\n",
        "mae_base = mean_absolute_error(y_test, y_pred_base)\n",
        "rmse_base = np.sqrt(mean_squared_error(y_test, y_pred_base))\n",
        "r2_base = r2_score(y_test, y_pred_base)\n",
        "\n",
        "print(\"Бейзлайн\")\n",
        "print(\"MAE:\", mae_base)\n",
        "print(\"RMSE:\", rmse_base)\n",
        "print(\"R^2:\", r2_base)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTOjPmi8hJWV",
        "outputId": "c4798552-d55f-4182-b7d5-e9ea9365146c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Бейзлайн\n",
            "MAE: 9.652318332589692\n",
            "RMSE: 11.372057025055133\n",
            "R^2: 0.28498603386590127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Первая гипотеза - улучшим качество за счет подбора гиперпараметров соседей и типа весов. Используем GridSearchCV с минимизацией MAE"
      ],
      "metadata": {
        "id": "coArHMROha8G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подбираю коэффициент регуляризации α для Ridge-регрессии по MAE на кросс-валидации. Лучшим оказалось значение 10. На тесте модель даёт MAE ≈ 9.58, RMSE ≈ 11.32 и R^2 ≈ 0.29. По сравнению с бейзлайном линейной регрессии качество немного улучшилось. Ошибка слегка снизилась, а доля объяснённой дисперсии выросла. Регуляризация L2 помогает чуть стабилизировать модель, но прирост качества остаётся умеренным"
      ],
      "metadata": {
        "id": "zQzJkw2qnP0f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ridge_pipe = Pipeline(steps=[\n",
        "    (\"preprocess\", preprocessor_reg),\n",
        "    (\"model\", Ridge(random_state=42))\n",
        "])\n",
        "\n",
        "param_grid_ridge = {\n",
        "    \"model__alpha\": [0.01, 0.1, 1.0, 3.0, 10.0, 30.0, 100.0]\n",
        "}\n",
        "\n",
        "ridge_gs = GridSearchCV(\n",
        "    estimator=ridge_pipe,\n",
        "    param_grid=param_grid_ridge,\n",
        "    scoring=\"neg_mean_absolute_error\",\n",
        "    cv=3,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "ridge_gs.fit(X_train, y_train)\n",
        "\n",
        "print(\"Лучшие параметры:\", ridge_gs.best_params_)\n",
        "print(\"Лучший MAE на CV:\", -ridge_gs.best_score_)\n",
        "\n",
        "best_ridge = ridge_gs.best_estimator_\n",
        "y_pred_ridge = best_ridge.predict(X_test)\n",
        "\n",
        "mae_ridge = mean_absolute_error(y_test, y_pred_ridge)\n",
        "rmse_ridge = np.sqrt(mean_squared_error(y_test, y_pred_ridge))\n",
        "r2_ridge = r2_score(y_test, y_pred_ridge)\n",
        "\n",
        "print(\"\\nRidge-регрессия\")\n",
        "print(\"MAE:\", mae_ridge)\n",
        "print(\"RMSE:\", rmse_ridge)\n",
        "print(\"R^2:\", r2_ridge)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PK2z7OW1hbD9",
        "outputId": "a09bc32d-f58e-4efe-e3c3-6521e15581d8"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лучшие параметры: {'model__alpha': 10.0}\n",
            "Лучший MAE на CV: 9.397653665287969\n",
            "\n",
            "Ridge-регрессия\n",
            "MAE: 9.57618614916091\n",
            "RMSE: 11.321007730022512\n",
            "R^2: 0.2913910373260141\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Гипотеза 2 - взять вместо расстояния до метро его логарифм, так как в распределении данные неравномерные"
      ],
      "metadata": {
        "id": "NMN7IG1nhmWY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "На кросс-валидации лучшим оказалось очень маленькое значение регуляризации, но на тестовой выборке качество заметно ухудшилось: MAE вырос до ≈10.46, RMSE до ≈12.19, а R² упал до ≈0.18. Это говорит о том, что логарифмирование расстояния до MRT в такой постановке задачи не помогает модели, а, скорее всего, приводит к переобучению под валидационные разбиения и ухудшению обобщающей способности"
      ],
      "metadata": {
        "id": "FgY9Dw21nsQw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_log = df.copy()\n",
        "df_log[\"log_dist_MRT\"] = np.log1p(df_log[\"Distance to the nearest MRT station\"])\n",
        "\n",
        "features_log = [\n",
        "    \"House age\",\n",
        "    \"log_dist_MRT\",\n",
        "    \"Number of convenience stores\",\n",
        "    \"Latitude\",\n",
        "    \"Longitude\",\n",
        "]\n",
        "\n",
        "X_log = df_log[features_log]\n",
        "y_log = df_log[\"House price of unit area\"]\n",
        "\n",
        "X_train_log, X_test_log, y_train_log, y_test_log = train_test_split(\n",
        "    X_log, y_log,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "preprocessor_log = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", StandardScaler(), features_log),\n",
        "    ]\n",
        ")\n",
        "\n",
        "ridge_log_pipe = Pipeline(steps=[\n",
        "    (\"preprocess\", preprocessor_log),\n",
        "    (\"model\", Ridge(random_state=42))\n",
        "])\n",
        "\n",
        "param_grid_ridge_log = {\n",
        "    \"model__alpha\": [0.01, 0.1, 1.0, 3.0, 10.0, 30.0, 100.0]\n",
        "}\n",
        "\n",
        "ridge_log_gs = GridSearchCV(\n",
        "    estimator=ridge_log_pipe,\n",
        "    param_grid=param_grid_ridge_log,\n",
        "    scoring=\"neg_mean_absolute_error\",\n",
        "    cv=3,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "ridge_log_gs.fit(X_train_log, y_train_log)\n",
        "\n",
        "print(\"Лучшие параметры:\", ridge_log_gs.best_params_)\n",
        "print(\"Лучший MAE на CV:\", -ridge_log_gs.best_score_)\n",
        "\n",
        "best_ridge_log = ridge_log_gs.best_estimator_\n",
        "y_pred_log = best_ridge_log.predict(X_test_log)\n",
        "\n",
        "mae_log = mean_absolute_error(y_test_log, y_pred_log)\n",
        "rmse_log = np.sqrt(mean_squared_error(y_test_log, y_pred_log))\n",
        "r2_log = r2_score(y_test_log, y_pred_log)\n",
        "\n",
        "print(\"\\nRidge-регрессия\")\n",
        "print(\"MAE:\", mae_log)\n",
        "print(\"RMSE:\", rmse_log)\n",
        "print(\"R^2:\", r2_log)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7bmMTJ1hl7T",
        "outputId": "d85d1af0-6212-4716-b038-6b52c94d33db"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лучшие параметры: {'model__alpha': 0.01}\n",
            "Лучший MAE на CV: 9.671738022270157\n",
            "\n",
            "Ridge-регрессия\n",
            "MAE: 10.461407475833552\n",
            "RMSE: 12.193956351577775\n",
            "R^2: 0.17789793424285816\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3 гипотеза - логарифмирование таргета может помочь уменьшить влияние дорогих объектов  \n",
        "MAE ≈ 10.17, RMSE ≈ 11.70 и R^2 ≈ 0.24 - все три показателя хуже, чем у базового линейного бейзлайна и особенно хуже, чем у Ridge без логарифмирования. То есть для этого датасета логарифмирование таргета в линейной модели скорее портит качество, чем улучшает его, и более разумным выбором остаётся обычная Ridge-регрессия без трансформации цены"
      ],
      "metadata": {
        "id": "XOqVzVxshtEG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_log_target = np.log1p(df[\"House price of unit area\"])\n",
        "X_t = df.drop(columns=[\"House price of unit area\", \"Transaction date\"])\n",
        "\n",
        "X_train_t, X_test_t, y_train_t, y_test_t = train_test_split(\n",
        "    X_t, y_log_target,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "num_cols_t = X_t.columns.tolist()\n",
        "\n",
        "preprocessor_t = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", StandardScaler(), num_cols_t),\n",
        "    ]\n",
        ")\n",
        "\n",
        "ridge_log_target_pipe = Pipeline(steps=[\n",
        "    (\"preprocess\", preprocessor_t),\n",
        "    (\"model\", Ridge(random_state=42))\n",
        "])\n",
        "\n",
        "param_grid_ridge_t = {\n",
        "    \"model__alpha\": [0.01, 0.1, 1.0, 3.0, 10.0, 30.0, 100.0]\n",
        "}\n",
        "\n",
        "ridge_log_target_gs = GridSearchCV(\n",
        "    estimator=ridge_log_target_pipe,\n",
        "    param_grid=param_grid_ridge_t,\n",
        "    scoring=\"neg_mean_absolute_error\",\n",
        "    cv=3,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "ridge_log_target_gs.fit(X_train_t, y_train_t)\n",
        "\n",
        "print(\"Лучшие параметры:\", ridge_log_target_gs.best_params_)\n",
        "print(\"Лучший MAE на CV:\", -ridge_log_target_gs.best_score_)\n",
        "\n",
        "best_ridge_t = ridge_log_target_gs.best_estimator_\n",
        "\n",
        "y_pred_log_t = best_ridge_t.predict(X_test_t)\n",
        "y_pred_t = np.expm1(y_pred_log_t)\n",
        "\n",
        "y_test_true = np.expm1(y_test_t)\n",
        "\n",
        "mae_log_t = mean_absolute_error(y_test_true, y_pred_t)\n",
        "rmse_log_t = np.sqrt(mean_squared_error(y_test_true, y_pred_t))\n",
        "r2_log_t = r2_score(y_test_true, y_pred_t)\n",
        "\n",
        "print(\"\\nRidge-регрессия с логарифмом таргета\")\n",
        "print(\"MAE:\", mae_log_t)\n",
        "print(\"RMSE:\", rmse_log_t)\n",
        "print(\"R^2:\", r2_log_t)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oW_9-mBfhtL0",
        "outputId": "c28b8f7a-06eb-47b2-ab55-41c2ba21ad7f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лучшие параметры: {'model__alpha': 10.0}\n",
            "Лучший MAE на CV: 0.3477069719356893\n",
            "\n",
            "Ridge-регрессия с логарифмом таргета\n",
            "MAE: 10.17089597304163\n",
            "RMSE: 11.698286412394637\n",
            "R^2: 0.2433745112489608\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Реализую собственную линейную регрессию  \n",
        "Модель поддерживает опцию свободного члена, L2-регуляризацию через параметры penalty=\"l2\" и alpha, а также обучение градиентным спуском. В fit инициализирую веса, считаю предсказания, градиенты MSE-функции потерь (с добавлением L2-штрафа) и обновляю параметры. В predict возвращаю линейную комбинацию признаков и обученных коэффициентов"
      ],
      "metadata": {
        "id": "iYxJV1q8i_D4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyLinearRegression(BaseEstimator, RegressorMixin):\n",
        "    def __init__(\n",
        "        self,\n",
        "        lr=0.01,\n",
        "        n_iter=1000,\n",
        "        fit_intercept=True,\n",
        "        penalty=\"none\",  # 'none' или 'l2'\n",
        "        alpha=0.0,\n",
        "        random_state=None\n",
        "    ):\n",
        "        self.lr = lr\n",
        "        self.n_iter = n_iter\n",
        "        self.fit_intercept = fit_intercept\n",
        "        self.penalty = penalty\n",
        "        self.alpha = alpha\n",
        "        self.random_state = random_state\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        X = np.asarray(X)\n",
        "        y = np.asarray(y)\n",
        "\n",
        "        n_samples, n_features = X.shape\n",
        "\n",
        "        rng = np.random.RandomState(self.random_state)\n",
        "        self.w_ = rng.normal(scale=0.01, size=n_features)\n",
        "        self.b_ = 0.0 if self.fit_intercept else 0.0\n",
        "\n",
        "        if self.penalty == \"l2\":\n",
        "            lam = float(self.alpha)\n",
        "        elif self.penalty in [\"none\", None]:\n",
        "            lam = 0.0\n",
        "        else:\n",
        "            raise ValueError(\"поддерживаются только penalty='l2' или 'none'\")\n",
        "\n",
        "        for _ in range(self.n_iter):\n",
        "            y_pred = X @ self.w_ + (self.b_ if self.fit_intercept else 0.0)\n",
        "            error = y_pred - y\n",
        "\n",
        "            grad_w = X.T @ error / n_samples + lam * self.w_\n",
        "            if self.fit_intercept:\n",
        "                grad_b = error.mean()\n",
        "            else:\n",
        "                grad_b = 0.0\n",
        "\n",
        "            self.w_ -= self.lr * grad_w\n",
        "            if self.fit_intercept:\n",
        "                self.b_ -= self.lr * grad_b\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        X = np.asarray(X)\n",
        "        return X @ self.w_ + (self.b_ if self.fit_intercept else 0.0)"
      ],
      "metadata": {
        "id": "LHdauFiii_qD"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Строю бейзлайн на собственной линейной регрессии, использую те же признаки, разбиение train/test и стандартизацию, что и для библиотечной модели. В пайплайне вместо модели из sklearn подключаю MyLinearRegression без регуляризации"
      ],
      "metadata": {
        "id": "F-5jK3RkjahH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ошибки и коэффициент детерминации практически совпадают с результатами библиотечной модели, поэтому реализацию можно считать корректной: модель в среднем ошибается примерно на 9–10 единиц цены за квадратный метр и объясняет около 28 % вариации стоимости, то есть даёт базовое, но далёкое от идеального качество"
      ],
      "metadata": {
        "id": "c-XBepvuywF_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = df[\"House price of unit area\"]\n",
        "X = df.drop(columns=[\"House price of unit area\", \"Transaction date\"])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "num_cols = X.columns.tolist()\n",
        "\n",
        "preprocessor_reg = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", StandardScaler(), num_cols),\n",
        "    ]\n",
        ")\n",
        "\n",
        "my_lin_base = Pipeline(steps=[\n",
        "    (\"preprocess\", preprocessor_reg),\n",
        "    (\"model\", MyLinearRegression(\n",
        "        lr=0.01,\n",
        "        n_iter=3000,\n",
        "        fit_intercept=True,\n",
        "        penalty=\"none\",\n",
        "        alpha=0.0,\n",
        "        random_state=42\n",
        "    ))\n",
        "])\n",
        "\n",
        "my_lin_base.fit(X_train, y_train)\n",
        "y_pred_my_base = my_lin_base.predict(X_test)\n",
        "\n",
        "mae_my_base = mean_absolute_error(y_test, y_pred_my_base)\n",
        "rmse_my_base = np.sqrt(mean_squared_error(y_test, y_pred_my_base))\n",
        "r2_my_base = r2_score(y_test, y_pred_my_base)\n",
        "\n",
        "print(\"Бейзлайн MyLinearRegression\")\n",
        "print(\"MAE:\", mae_my_base)\n",
        "print(\"RMSE:\", rmse_my_base)\n",
        "print(\"R^2:\", r2_my_base)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmTS_58ZjaPR",
        "outputId": "e233f80d-be32-4827-af8b-e33bc308088a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Бейзлайн MyLinearRegression\n",
            "MAE: 9.65231833255961\n",
            "RMSE: 11.372057025050223\n",
            "R^2: 0.28498603386651855\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Гипотеза 1"
      ],
      "metadata": {
        "id": "fJjx7jI3jrB9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Качество почти не изменилось относительно бейзлайна: MAE снизился с 9.65 до 9.63, RMSE немного уменьшился, а R^2 вырос с 0.285 до 0.287. То есть слабая L2-регуляризация даёт лишь лёгкое сглаживание весов и совсем небольшое улучшение, что в целом совпадает с поведением библиотечной Ridge-регрессии"
      ],
      "metadata": {
        "id": "Y9x0aDe0zMYq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_ridge_pipe = Pipeline(steps=[\n",
        "    (\"preprocess\", preprocessor_reg),\n",
        "    (\"model\", MyLinearRegression(\n",
        "        lr=0.01,\n",
        "        n_iter=3000,\n",
        "        fit_intercept=True,\n",
        "        penalty=\"l2\",\n",
        "        alpha=1.0,\n",
        "        random_state=42\n",
        "    ))\n",
        "])\n",
        "\n",
        "param_grid_my1 = {\n",
        "    \"model__alpha\": [0.0, 0.01, 0.1, 1.0, 3.0, 10.0, 30.0, 100.0],\n",
        "    \"model__penalty\": [\"l2\"]\n",
        "}\n",
        "\n",
        "my_ridge_gs = GridSearchCV(\n",
        "    estimator=my_ridge_pipe,\n",
        "    param_grid=param_grid_my1,\n",
        "    scoring=\"neg_mean_absolute_error\",\n",
        "    cv=3,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "my_ridge_gs.fit(X_train, y_train)\n",
        "\n",
        "print(\"Лучшие параметры\", my_ridge_gs.best_params_)\n",
        "print(\"Лучший MAE на CV:\", -my_ridge_gs.best_score_)\n",
        "\n",
        "best_my_ridge = my_ridge_gs.best_estimator_\n",
        "y_pred_my_ridge = best_my_ridge.predict(X_test)\n",
        "\n",
        "mae_my_ridge = mean_absolute_error(y_test, y_pred_my_ridge)\n",
        "rmse_my_ridge = np.sqrt(mean_squared_error(y_test, y_pred_my_ridge))\n",
        "r2_my_ridge = r2_score(y_test, y_pred_my_ridge)\n",
        "\n",
        "print(\"\\nГипотеза 1\")\n",
        "print(\"MAE:\", mae_my_ridge)\n",
        "print(\"RMSE:\", rmse_my_ridge)\n",
        "print(\"R^2:\", r2_my_ridge)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frby_DM5jrQM",
        "outputId": "6eb99637-72fa-471a-ba3b-5e4e68a38c68"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лучшие параметры {'model__alpha': 0.01, 'model__penalty': 'l2'}\n",
            "Лучший MAE на CV: 9.406585001772603\n",
            "\n",
            "Гипотеза 1\n",
            "MAE: 9.62842947066716\n",
            "RMSE: 11.354835524871307\n",
            "R^2: 0.28714998528470204\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Гипотеза 2"
      ],
      "metadata": {
        "id": "r92pqFl8jwEi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Итоговое качество на тесте заметно ухудшилось. MAE вырос примерно до 10.46, RMSE до 12.19, а R^2 упал до 0.18 по сравнению с бейзлайном. То есть для линейной модели такая логарифмическая трансформация признака скорее ломает исходную линейную связь с ценой, чем помогает"
      ],
      "metadata": {
        "id": "GVvBFTQSzW0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_log = df.copy()\n",
        "df_log[\"log_dist_MRT\"] = np.log1p(df_log[\"Distance to the nearest MRT station\"])\n",
        "\n",
        "features_log = [\n",
        "    \"House age\",\n",
        "    \"log_dist_MRT\",\n",
        "    \"Number of convenience stores\",\n",
        "    \"Latitude\",\n",
        "    \"Longitude\",\n",
        "]\n",
        "\n",
        "X_log = df_log[features_log]\n",
        "y_log = df_log[\"House price of unit area\"]\n",
        "\n",
        "X_train_log, X_test_log, y_train_log, y_test_log = train_test_split(\n",
        "    X_log, y_log,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "preprocessor_log = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", StandardScaler(), features_log),\n",
        "    ]\n",
        ")\n",
        "\n",
        "my_ridge_log_pipe = Pipeline(steps=[\n",
        "    (\"preprocess\", preprocessor_log),\n",
        "    (\"model\", MyLinearRegression(\n",
        "        lr=0.01,\n",
        "        n_iter=3000,\n",
        "        fit_intercept=True,\n",
        "        penalty=\"l2\",\n",
        "        alpha=1.0,\n",
        "        random_state=42\n",
        "    ))\n",
        "])\n",
        "\n",
        "param_grid_my2 = {\n",
        "    \"model__alpha\": [0.0, 0.01, 0.1, 1.0, 3.0, 10.0, 30.0, 100.0],\n",
        "    \"model__penalty\": [\"l2\"]\n",
        "}\n",
        "\n",
        "my_ridge_log_gs = GridSearchCV(\n",
        "    estimator=my_ridge_log_pipe,\n",
        "    param_grid=param_grid_my2,\n",
        "    scoring=\"neg_mean_absolute_error\",\n",
        "    cv=3,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "my_ridge_log_gs.fit(X_train_log, y_train_log)\n",
        "\n",
        "print(\"Лучшие параметры:\", my_ridge_log_gs.best_params_)\n",
        "print(\"Лучший MAE на CV\", -my_ridge_log_gs.best_score_)\n",
        "\n",
        "best_my_ridge_log = my_ridge_log_gs.best_estimator_\n",
        "y_pred_my_log = best_my_ridge_log.predict(X_test_log)\n",
        "\n",
        "mae_my_log = mean_absolute_error(y_test_log, y_pred_my_log)\n",
        "rmse_my_log = np.sqrt(mean_squared_error(y_test_log, y_pred_my_log))\n",
        "r2_my_log = r2_score(y_test_log, y_pred_my_log)\n",
        "\n",
        "print(\"\\nГипотеза 2\")\n",
        "print(\"MAE:\", mae_my_log)\n",
        "print(\"RMSE:\", rmse_my_log)\n",
        "print(\"R^2:\", r2_my_log)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChAYuTIcjv2f",
        "outputId": "1f92185c-5c7c-4999-99cd-91c3cf872368"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лучшие параметры: {'model__alpha': 0.0, 'model__penalty': 'l2'}\n",
            "Лучший MAE на CV 9.671727293936891\n",
            "\n",
            "Гипотеза 2\n",
            "MAE: 10.461453823842039\n",
            "RMSE: 12.194004511546039\n",
            "R^2: 0.177891440454224\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Гипотеза 3"
      ],
      "metadata": {
        "id": "lP6kcvpLj0jk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подбор регуляризации (L2, α = 0.1) дал на кросс-валидации очень низкий MAE в лог-масштабе, но на реальных ценах улучшения не получилось. MAE даже немного вырос (≈9.89 против ≈9.65 у бейзлайна), а RMSE и R^2 изменились совсем незначительно (RMSE ≈11.35, R² ≈0.287)"
      ],
      "metadata": {
        "id": "TLla-T-mzzW0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_log_target = np.log1p(df[\"House price of unit area\"])\n",
        "X_t = df.drop(columns=[\"House price of unit area\", \"Transaction date\"])\n",
        "\n",
        "X_train_t, X_test_t, y_train_t, y_test_t = train_test_split(\n",
        "    X_t, y_log_target,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "num_cols_t = X_t.columns.tolist()\n",
        "\n",
        "preprocessor_t = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", StandardScaler(), num_cols_t),\n",
        "    ]\n",
        ")\n",
        "\n",
        "my_ridge_log_target_pipe = Pipeline(steps=[\n",
        "    (\"preprocess\", preprocessor_t),\n",
        "    (\"model\", MyLinearRegression(\n",
        "        lr=0.01,\n",
        "        n_iter=3000,\n",
        "        fit_intercept=True,\n",
        "        penalty=\"l2\",\n",
        "        alpha=1.0,\n",
        "        random_state=42\n",
        "    ))\n",
        "])\n",
        "\n",
        "param_grid_my3 = {\n",
        "    \"model__alpha\": [0.0, 0.01, 0.1, 1.0, 3.0, 10.0, 30.0, 100.0],\n",
        "    \"model__penalty\": [\"l2\"]\n",
        "}\n",
        "\n",
        "my_ridge_log_target_gs = GridSearchCV(\n",
        "    estimator=my_ridge_log_target_pipe,\n",
        "    param_grid=param_grid_my3,\n",
        "    scoring=\"neg_mean_absolute_error\",\n",
        "    cv=3,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "my_ridge_log_target_gs.fit(X_train_t, y_train_t)\n",
        "\n",
        "print(\"Лучшие параметры:\", my_ridge_log_target_gs.best_params_)\n",
        "print(\"Лучший MAE на CV:\", -my_ridge_log_target_gs.best_score_)\n",
        "\n",
        "best_my_ridge_t = my_ridge_log_target_gs.best_estimator_\n",
        "\n",
        "y_pred_log_t = best_my_ridge_t.predict(X_test_t)\n",
        "y_pred_t = np.expm1(y_pred_log_t)\n",
        "\n",
        "y_test_true = np.expm1(y_test_t)\n",
        "\n",
        "mae_my_log_t = mean_absolute_error(y_test_true, y_pred_t)\n",
        "rmse_my_log_t = np.sqrt(mean_squared_error(y_test_true, y_pred_t))\n",
        "r2_my_log_t = r2_score(y_test_true, y_pred_t)\n",
        "\n",
        "print(\"\\nГипотеза 3\")\n",
        "print(\"MAE:\", mae_my_log_t)\n",
        "print(\"RMSE:\", rmse_my_log_t)\n",
        "print(\"R^2:\", r2_my_log_t)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZiBDEM9j0UP",
        "outputId": "cfceeb53-8bab-4c26-8ebc-d37fcee1a609"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лучшие параметры: {'model__alpha': 0.1, 'model__penalty': 'l2'}\n",
            "Лучший MAE на CV: 0.34755402523057105\n",
            "\n",
            "Гипотеза 3\n",
            "MAE: 9.885303321187472\n",
            "RMSE: 11.353969887126523\n",
            "R^2: 0.2872586696168604\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Простой бейзлайн даёт адекватное качество с MAE около 9.6–9.7 и R^2 примерно 0.28. Добавление L2-регуляризации и подбор коэффициента α через кросс-валидацию позволяют чуть стабилизировать модель и совсем немного улучшить метрики, но без резкого скачка качества. Логарифмирование расстояния до MRT, как и раньше, только ухудшает результат, а логарифмирование таргета в линейной регрессии уже не даёт такого выигрыша, как в KNN: на MAE и RMSE эффект почти нейтральный. Собственная реализация линейной регрессии по качеству практически совпадает с библиотечной Ridge-моделью, так что её можно считать корректной"
      ],
      "metadata": {
        "id": "dArWIZ7h0D-i"
      }
    }
  ]
}