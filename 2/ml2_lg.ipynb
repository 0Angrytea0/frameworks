{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DsMItfal5qub"
      },
      "outputs": [],
      "source": [
        "#KGAT_746a8c48819a19cbaf8ca0048244831b"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opendatasets\n",
        "!pip install pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uC0VBKau6rnw",
        "outputId": "f39f0bfa-b8b5-487b-a372-149346a12a84"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from opendatasets) (4.67.1)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (from opendatasets) (1.7.4.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from opendatasets) (8.3.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (6.3.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2025.11.12)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (3.4.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (3.11)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (0.5.1)\n",
            "Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.22\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Библиотеки"
      ],
      "metadata": {
        "id": "9lOTIqwXIDNr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, classification_report\n",
        "from sklearn.utils.validation import check_array"
      ],
      "metadata": {
        "id": "881pyB2M6sHG"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Скачиваем датасет"
      ],
      "metadata": {
        "id": "CfZo9BS3IHl_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для задачи классификации был взят датасет с данными сайта MyAnimeList. В нём содержится информация об аниме-тайтлах: название, жанры, студии, тип (TV/OVA/фильм и т.д.), сезон выхода, демографический таргет, количество эпизодов, число участников в списках (Members) и другие признаки.\n",
        "Практическая задача: предсказать, будет ли аниме успешным с точки зрения зрителей. Данная задача применима с практической точки зрения для многих компаний, решающих, в какой проект вложить деньги для последующей прибыли от популярности тайтла."
      ],
      "metadata": {
        "id": "0K4dDVA0KOC8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "od.download(\"https://www.kaggle.com/datasets/syahrulapriansyah2/myanimelist-2025\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-QqdEUC6t2_",
        "outputId": "6bac9388-8950-4f28-cb4a-3d1d37ed16bb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: angrytea\n",
            "Your Kaggle Key: ··········\n",
            "Dataset URL: https://www.kaggle.com/datasets/syahrulapriansyah2/myanimelist-2025\n",
            "Downloading myanimelist-2025.zip to ./myanimelist-2025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.57M/9.57M [00:00<00:00, 835MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Чтение датасета и просмотр столбцов  \n",
        "Удаляем строки, не имеющие в Members значения  \n",
        "Задаем условие успешности: тайтл успешный, если у него 75% и больше зрителей: 1 - аниме успешное (собрало много просмотров) 0 - не успешное  \n",
        "Для признаков возьмем Source, Type, Released_Season, Episodes, Genres, Studios, Demographic  \n",
        "Пропуски по эпизодам заменяем медианой, по категориальным признакам на Unknown, жанрам и студиям поставим пустые строки  \n",
        "Создаем список жанров  \n",
        "Ищем самые популярные жанры и делаем для них колонки  \n",
        "Список студий делаем  \n",
        "Ищем популярные студии, не учитывая 'add some'  \n",
        "Задаем колонки  \n",
        "Собираем матрицу X из фич и назначаем целевую переменную успешности y  \n",
        "Делим данные на train и test  \n",
        "Числовые и бинарные признаки будем масштабировать, а для категориальных используем one-hot encoding"
      ],
      "metadata": {
        "id": "He5aBRv1LR0k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option(\"display.max_columns\", None)\n",
        "df = pd.read_csv(\"myanimelist-2025/mal_anime.csv\")\n",
        "df.info()\n",
        "\n",
        "df[\"Members\"] = pd.to_numeric(df[\"Members\"], errors=\"coerce\")\n",
        "df = df.dropna(subset=[\"Members\"])\n",
        "\n",
        "th = df[\"Members\"].quantile(0.75)\n",
        "df[\"hit\"] = (df[\"Members\"] >= th).astype(int)\n",
        "\n",
        "df[\"Episodes\"] = pd.to_numeric(df[\"Episodes\"], errors=\"coerce\")\n",
        "m_episodes = df[\"Episodes\"].median()\n",
        "df[\"Episodes\"] = df[\"Episodes\"].fillna(m_episodes)\n",
        "\n",
        "for col in [\"Source\", \"Type\", \"Released_Season\", \"Demographic\"]:\n",
        "    df[col] = df[col].fillna(\"Unknown\")\n",
        "\n",
        "for col in [\"Genres\", \"Studios\"]: df[col] = df[col].fillna(\"\")\n",
        "\n",
        "df[\"Genres_l\"] = df[\"Genres\"].apply(lambda x: [i.strip() for i in str(x).split(\",\") if i.strip() != \"\"])\n",
        "genre_count = Counter()\n",
        "\n",
        "for g in df[\"Genres_l\"]:\n",
        "    genre_count.update(g)\n",
        "\n",
        "top_g = [i for i, _ in genre_count.most_common(10)]\n",
        "\n",
        "for g in top_g:\n",
        "    col_name = f\"genre_{g}\"\n",
        "    df[col_name] = df[\"Genres_l\"].apply(lambda lst: int(g in lst))\n",
        "\n",
        "g_cols = [f\"genre_{g}\" for g in top_g]\n",
        "df[g_cols].head()\n",
        "\n",
        "df[\"Studios_l\"] = df[\"Studios\"].apply(lambda x: [i.strip() for i in str(x).split(\",\") if i.strip() != \"\"])\n",
        "studio_count = Counter()\n",
        "for s in df[\"Studios_l\"]:\n",
        "  for st in s:\n",
        "    clean_s = st.strip()\n",
        "    if \"add some\" in clean_s.lower(): continue\n",
        "    studio_count[clean_s] += 1\n",
        "\n",
        "top_s = [i for i, _ in studio_count.most_common(10)]\n",
        "\n",
        "for s in top_s:\n",
        "    col_name = f\"studio_{s}\"\n",
        "    df[col_name] = df[\"Studios_l\"].apply(lambda lst: int(s in lst))\n",
        "\n",
        "studio_cols = [f\"studio_{s}\" for s in top_s]\n",
        "\n",
        "num = [\"Episodes\"] + g_cols + studio_cols\n",
        "categ = [\"Source\", \"Type\", \"Released_Season\", \"Demographic\"]\n",
        "feature = num + categ\n",
        "\n",
        "X = df[feature]\n",
        "y = df[\"hit\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42,stratify=y)\n",
        "\n",
        "pred = ColumnTransformer(transformers=[\n",
        "    (\"num\", StandardScaler(),num),\n",
        "    (\"categ\", OneHotEncoder(handle_unknown=\"ignore\"), categ)\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huiyuf5o6u6K",
        "outputId": "37773a6f-3b1e-4331-c997-a2c2d1ae93e2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 19931 entries, 0 to 19930\n",
            "Data columns (total 25 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   myanimelist_id   19931 non-null  int64  \n",
            " 1   title            19931 non-null  object \n",
            " 2   description      19875 non-null  object \n",
            " 3   image            19544 non-null  object \n",
            " 4   Type             19534 non-null  object \n",
            " 5   Episodes         19549 non-null  object \n",
            " 6   Status           19549 non-null  object \n",
            " 7   Premiered        6343 non-null   object \n",
            " 8   Released_Season  6182 non-null   object \n",
            " 9   Released_Year    6182 non-null   float64\n",
            " 10  Source           19166 non-null  object \n",
            " 11  Genres           18270 non-null  object \n",
            " 12  Themes           11217 non-null  object \n",
            " 13  Studios          19549 non-null  object \n",
            " 14  Producers        19549 non-null  object \n",
            " 15  Demographic      6522 non-null   object \n",
            " 16  Duration         19549 non-null  object \n",
            " 17  Rating           19057 non-null  object \n",
            " 18  Score            15239 non-null  float64\n",
            " 19  Ranked           17406 non-null  object \n",
            " 20  Popularity       19549 non-null  object \n",
            " 21  Members          19549 non-null  object \n",
            " 22  Favorites        19549 non-null  object \n",
            " 23  characters       13519 non-null  object \n",
            " 24  source_url       19931 non-null  object \n",
            "dtypes: float64(2), int64(1), object(22)\n",
            "memory usage: 3.8+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Строим бейзлайн  \n"
      ],
      "metadata": {
        "id": "UpLV2yMc7gPm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Затем обучается LogisticRegression со стандартными настройками.  \n",
        "После обучения на X_train, y_train считаю предсказания на тесте и оцениваю качество по метрикам Accuracy, F1-score (для класса hit), ROC-AUC, а также вывожу подробный classification_report по каждому классу"
      ],
      "metadata": {
        "id": "1Dx_rNDsNHwR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Получаем Accuracy ≈ 0.77, что чуть выше, чем доля класса 0 в выборке (около 0.75). Это значит, что модель использует информацию из признаков и работает немного лучше, чем тривиальный классификатор, всегда предсказывающий «не hit».\n",
        "По целевому классу hit метрики заметно хуже: F1 ≈ 0.26 при precision ≈ 0.63 и recall ≈ 0.17. То есть, если модель всё-таки предсказывает hit, она в большинстве случаев права (достаточно высокая точность), но реальных успешных тайтлов она находит очень мало - всего около 17 % (очень низкая полнота). Это свидетельствует о сильном перекосе в сторону класса 0 и консервативном принятии решения о том, что тайтл является hit  \n",
        "Значение ROC-AUC ≈ 0.71 показывает, что по непривязанным к порогу вероятностям модель различает классы значительно лучше случайного угадывания (0.5), но при стандартном пороге 0.5 баланс между precision и recall для класса hit остаётся неудовлетворительным"
      ],
      "metadata": {
        "id": "r9iMbKajIBYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "log_base = Pipeline(steps=[\n",
        "    (\"pred\", pred),\n",
        "    (\"classifier\", LogisticRegression(max_iter=1000, n_jobs=-1, random_state=42))\n",
        "])\n",
        "\n",
        "log_base.fit(X_train, y_train)\n",
        "\n",
        "y_pred_log = log_base.predict(X_test)\n",
        "y_proba_log = log_base.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"бейзлайн\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_log))\n",
        "print(\"F1-score:\", f1_score(y_test, y_pred_log))\n",
        "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba_log))\n",
        "print()\n",
        "print(classification_report(y_test, y_pred_log))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpjyoU9d7vzy",
        "outputId": "3f813b56-4a25-402c-8cd8-ca720bc7d73d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "бейзлайн\n",
            "Accuracy: 0.7668049792531121\n",
            "F1-score: 0.26246719160104987\n",
            "ROC-AUC: 0.7057600492838443\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.97      0.86       903\n",
            "           1       0.63      0.17      0.26       302\n",
            "\n",
            "    accuracy                           0.77      1205\n",
            "   macro avg       0.70      0.57      0.56      1205\n",
            "weighted avg       0.74      0.77      0.71      1205\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1 гипотеза - подбираем гиперпараметры с помощью GridSearchCV  \n",
        "В сетке перебираю коэффициент регуляризации C и параметр class_weigh, фиксируя L2-регуляризацию. В качестве целевой метрики использую f1 по классу hit, кросс-валидация - 3-кратная. После подбора параметров обучаю лучшую модель на train, считаю предсказания на тесте"
      ],
      "metadata": {
        "id": "lsQYWRnJ29st"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GridSearchCV выбирает конфигурацию с L2-регуляризацией, C = 0.1 и class_weight='balanced'  \n",
        "Accuracy падает с 0.77 до 0.67, зато F1 по классу hit заметно растёт с 0.26 до 0.47, а recall для hit увеличивается примерно с 0.17 до 0.59. Это означает, что модель стала гораздо лучше меньше пропускать хиты, пусть и ценой большего числа ошибок по классу 0 и общего снижения Accuracy. ROC-AUC остаётся примерно на том же уровне 0.70, то есть общая способность разграничивать классы по вероятностям не ухудшилась, меняется именно баланс ошибок между классами"
      ],
      "metadata": {
        "id": "mvSTx777IPby"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid_log1 = {\n",
        "    \"classifier__penalty\": [\"l2\"],\n",
        "    \"classifier__C\": [0.01, 0.1, 1.0, 3.0, 10.0],\n",
        "    \"classifier__class_weight\": [None, \"balanced\"],\n",
        "}\n",
        "\n",
        "log_clf1 = Pipeline(steps=[\n",
        "    (\"pred\", pred),\n",
        "    (\"classifier\", LogisticRegression(\n",
        "        max_iter=1000,\n",
        "        n_jobs=-1,\n",
        "        random_state=42,\n",
        "        solver=\"lbfgs\"\n",
        "    ))\n",
        "])\n",
        "\n",
        "grid_log1 = GridSearchCV(\n",
        "    estimator=log_clf1,\n",
        "    param_grid=param_grid_log1,\n",
        "    scoring=\"f1\",\n",
        "    cv=3,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid_log1.fit(X_train, y_train)\n",
        "\n",
        "print(\"Лучшие параметры:\", grid_log1.best_params_)\n",
        "print(\"Лучший F1 на CV:\", grid_log1.best_score_)\n",
        "\n",
        "best_log1 = grid_log1.best_estimator_\n",
        "y_pred_log1 = best_log1.predict(X_test)\n",
        "y_proba_log1 = best_log1.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"\\nгипотеза 1\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_log1))\n",
        "print(\"F1-score:\", f1_score(y_test, y_pred_log1))\n",
        "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba_log1))\n",
        "print(classification_report(y_test, y_pred_log1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24jfnQrd8cBN",
        "outputId": "73bdf65c-b127-40df-d177-ebd181e2f7cf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лучшие параметры: {'classifier__C': 0.1, 'classifier__class_weight': 'balanced', 'classifier__penalty': 'l2'}\n",
            "Лучший F1 на CV: 0.48206640511691146\n",
            "\n",
            "гипотеза 1\n",
            "Accuracy: 0.6688796680497925\n",
            "F1-score: 0.4701195219123506\n",
            "ROC-AUC: 0.7041099205738047\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.70      0.76       903\n",
            "           1       0.39      0.59      0.47       302\n",
            "\n",
            "    accuracy                           0.67      1205\n",
            "   macro avg       0.61      0.64      0.61      1205\n",
            "weighted avg       0.72      0.67      0.69      1205\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2 гипотеза  \n",
        "На основе log_Episodes, бинарных жанров и студий заново формирую матрицу признаков и разбиваю данные на train/test. Строю новый пайплайн с тем же препроцессингом (масштабирование чисел, one-hot для категорий) и логистической регрессией. С помощью GridSearchCV подбираю C и class_weight по метрике F1 для класса hit, обучаю лучшую модель и оцениваю качество на тесте (Accuracy, F1, ROC-AUC), чтобы понять, даёт ли логарифмирование эпизодов прирост по сравнению с предыдущей гипотезой"
      ],
      "metadata": {
        "id": "AkHe-jz05ySS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GridSearch снова выбирает те же оптимальные гиперпараметры, что и в гипотезе 1  \n",
        "Качество на тесте остаётся на очень близком уровне: F1 по классу hit ≈ 0.46 против 0.47 в предыдущей гипотезе, recall для hit немного падает (0.57 вместо 0.59), Accuracy и ROC-AUC почти не меняются. Это показывает, что логарифмирование количества эпизодов в текущей постановке не даёт заметного дополнительного выигрыша по сравнению с уже настроенной логистической регрессией с балансировкой классов"
      ],
      "metadata": {
        "id": "ssOhbfMpL2jV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df.copy()\n",
        "df2[\"log_Episodes\"] = np.log1p(df2[\"Episodes\"])\n",
        "\n",
        "num2 = [\"log_Episodes\"] + g_cols + studio_cols\n",
        "categ = [\"Source\", \"Type\", \"Released_Season\", \"Demographic\"]\n",
        "feature2 = num2 + categ\n",
        "\n",
        "X2 = df2[feature2]\n",
        "y2 = df2[\"hit\"]\n",
        "\n",
        "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2,test_size=0.2,random_state=42, stratify=y2)\n",
        "\n",
        "pred2 = ColumnTransformer(transformers=[\n",
        "    (\"num2\", StandardScaler(), num2),\n",
        "    (\"categ\", OneHotEncoder(handle_unknown=\"ignore\"), categ),\n",
        "])\n",
        "\n",
        "log_clf2 = Pipeline(steps=[\n",
        "    (\"pred\", pred2),\n",
        "    (\"classifier\", LogisticRegression(\n",
        "        max_iter=1000,\n",
        "        n_jobs=-1,\n",
        "        random_state=42\n",
        "    ))\n",
        "])\n",
        "\n",
        "grid_log2 = GridSearchCV(\n",
        "    estimator=log_clf2,\n",
        "    param_grid=param_grid_log1,\n",
        "    scoring=\"f1\",\n",
        "    cv=3,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid_log2.fit(X2_train,y2_train)\n",
        "\n",
        "print(\"Лучшие параметры:\", grid_log2.best_params_)\n",
        "print(\"Лучший F1 на CV:\", grid_log2.best_score_)\n",
        "\n",
        "best_log2 = grid_log2.best_estimator_\n",
        "y_pred_log2 = best_log2.predict(X2_test)\n",
        "y_proba_log2 = best_log2.predict_proba(X2_test)[:, 1]\n",
        "\n",
        "print(\"\\nЛогистическая регрессия + class_weight/С + log(Episodes)\")\n",
        "print(\"Accuracy:\", accuracy_score(y2_test, y_pred_log2))\n",
        "print(\"F1-score:\", f1_score(y2_test, y_pred_log2))\n",
        "print(\"ROC-AUC:\", roc_auc_score(y2_test, y_proba_log2))\n",
        "print(classification_report(y2_test, y_pred_log2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LK1twQM29K1E",
        "outputId": "557f2675-6e75-4b23-964d-556cba86212e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лучшие параметры: {'classifier__C': 0.1, 'classifier__class_weight': 'balanced', 'classifier__penalty': 'l2'}\n",
            "Лучший F1 на CV: 0.47723671193058953\n",
            "\n",
            "Логистическая регрессия + class_weight/С + log(Episodes)\n",
            "Accuracy: 0.6655601659751037\n",
            "F1-score: 0.46194926568758343\n",
            "ROC-AUC: 0.7013267034828716\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.70      0.76       903\n",
            "           1       0.39      0.57      0.46       302\n",
            "\n",
            "    accuracy                           0.67      1205\n",
            "   macro avg       0.61      0.63      0.61      1205\n",
            "weighted avg       0.72      0.67      0.68      1205\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Третья гипотеза  \n",
        "Пересчитываю самые частые жанры и студии, создаю бинарные признаки для top-20, формирую новый набор числовых признаков и категориальных. Далее заново делю данные на train/test, настраиваю ColumnTransformer (масштабирование числовых признаков и one-hot-кодирование категориальных) и обучаю логистическую регрессию"
      ],
      "metadata": {
        "id": "6C6-EMtu9UjM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GridSearch снова выбирает конфигурацию с C = 0.1 и class_weight='balanced'. На тесте F1 по классу hit остаётся на уровне ≈0.47, как и в первой гипотезе, но общая Accuracy немного растёт (с ~0.67 до ~0.68), при этом recall по hit держится около 0.57. ROC-AUC почти не меняется. Это означает, что добавление признаков для более широкого набора жанров и студий немного улучшает общую точность, но в целом не даёт серьёзного прироста качества по сравнению с уже настроенной моделью"
      ],
      "metadata": {
        "id": "sKlzv9PYMZkx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_s1 = [i for i, _ in studio_count.most_common(20)]\n",
        "for s in top_s1:\n",
        "    col_name = f\"studio_{s}\"\n",
        "    df[col_name] = df[\"Studios_l\"].apply(lambda lst: int(s in lst))\n",
        "\n",
        "studio_cols1 = [f\"studio_{s}\" for s in top_s1]\n",
        "\n",
        "top_g1 = [i for i, _ in genre_count.most_common(20)]\n",
        "\n",
        "for g in top_g1:\n",
        "    col_name = f\"genre_{g}\"\n",
        "    df[col_name] = df[\"Genres_l\"].apply(lambda lst: int(g in lst))\n",
        "\n",
        "g_cols1 = [f\"genre_{g}\" for g in top_g1]\n",
        "\n",
        "num = [\"Episodes\"] + g_cols1 + studio_cols1\n",
        "categ = [\"Source\", \"Type\", \"Released_Season\", \"Demographic\"]\n",
        "feature = num + categ\n",
        "\n",
        "X = df[feature]\n",
        "y = df[\"hit\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "pred = ColumnTransformer(transformers=[(\"num\", StandardScaler(), num), (\"categ\", OneHotEncoder(handle_unknown=\"ignore\"), categ)])\n",
        "\n",
        "model_n = Pipeline(steps=[\n",
        "    (\"pred\", pred),\n",
        "    (\"classifier\", LogisticRegression(\n",
        "        max_iter=1000,\n",
        "        n_jobs=-1,\n",
        "        random_state=42\n",
        "    ))\n",
        "])\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=model_n,\n",
        "    param_grid=param_grid_log1,\n",
        "    scoring=\"f1\",\n",
        "    cv=3,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Лучшие параметры:\", grid_search.best_params_)\n",
        "print(\"Лучший F1 на кросс-валидации:\", grid_search.best_score_)\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "y_pred = best_model.predict(X_test)\n",
        "y_proba = best_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "roc = roc_auc_score(y_test, y_proba)\n",
        "\n",
        "print(\"top-20 жанров/студий\")\n",
        "print(\"Accuracy:\", acc)\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"ROC-AUC:\", roc)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qud3a7tSA8-C",
        "outputId": "848db97c-9a7d-4b14-aec7-4029f3a0a229"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лучшие параметры: {'classifier__C': 0.1, 'classifier__class_weight': 'balanced', 'classifier__penalty': 'l2'}\n",
            "Лучший F1 на кросс-валидации: 0.4765046512668795\n",
            "top-20 жанров/студий\n",
            "Accuracy: 0.6771784232365146\n",
            "F1-score: 0.46785225718194257\n",
            "ROC-AUC: 0.702586301731535\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.71      0.77       903\n",
            "           1       0.40      0.57      0.47       302\n",
            "\n",
            "    accuracy                           0.68      1205\n",
            "   macro avg       0.61      0.64      0.62      1205\n",
            "weighted avg       0.72      0.68      0.69      1205\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Реализую собственную модель  \n",
        "Модель поддерживает L2-регуляризацию и учёт дисбаланса классов через class_weight=\"balanced\"  \n",
        "В fit привожу данные к плотному float-массиву, кодирую таргет в 0/1,инициализирую веса, оптимизирую логистическую функцию потерь с L2-штрафом с помощью полного градиентного спуска и sample_weight, после обучения подбираю оптимальный порог вероятности по F1 на обучающей выборке и сохраняю его в self.threshold_  \n",
        "В predict_proba возвращаю вероятности двух классов,\n",
        "а в predict перевожу их в метки классов, используя подобранный порог и обратно маппя 0/1 в исходные значения классов"
      ],
      "metadata": {
        "id": "K1c4PG7h939L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyLogisticRegression(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(\n",
        "        self,\n",
        "        lr=0.1,\n",
        "        n_iter=1000,\n",
        "        penalty=\"l2\",        # 'none' или 'l2'\n",
        "        C=1.0,\n",
        "        class_weight=None,   # None или 'balanced'\n",
        "        fit_intercept=True,\n",
        "        random_state=None\n",
        "    ):\n",
        "        self.lr = lr\n",
        "        self.n_iter = n_iter\n",
        "        self.penalty = penalty\n",
        "        self.C = C\n",
        "        self.class_weight = class_weight\n",
        "        self.fit_intercept = fit_intercept\n",
        "        self.random_state = random_state\n",
        "        self.threshold_ = 0.5\n",
        "\n",
        "    def _sigmoid(self, z):\n",
        "        z = np.clip(z, -30, 30)\n",
        "        return 1.0 / (1.0 + np.exp(-z))\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        X = check_array(X, accept_sparse=False, dtype=float)\n",
        "        y = np.asarray(y)\n",
        "\n",
        "        self.classes_ = np.unique(y)\n",
        "        if self.classes_.shape[0] != 2:\n",
        "            raise ValueError(\"MyLogisticRegression поддерживает только бинарную классификацию\")\n",
        "\n",
        "        y_bin = (y == self.classes_[1]).astype(float)\n",
        "\n",
        "        n_samples, n_features = X.shape\n",
        "        rng = np.random.RandomState(self.random_state)\n",
        "\n",
        "        self.w_ = rng.normal(scale=0.01, size=n_features)\n",
        "        self.b_ = 0.0\n",
        "\n",
        "        if self.class_weight is None:\n",
        "            sample_weight = np.ones(n_samples)\n",
        "        elif self.class_weight == \"balanced\":\n",
        "            n_pos = y_bin.sum()\n",
        "            n_neg = n_samples - n_pos\n",
        "            w0 = n_samples / (2.0 * n_neg)\n",
        "            w1 = n_samples / (2.0 * n_pos)\n",
        "            sample_weight = np.where(y_bin == 1.0, w1, w0)\n",
        "        else:\n",
        "            raise ValueError(\"class_weight должен быть None или 'balanced'\")\n",
        "\n",
        "        if self.penalty == \"l2\":\n",
        "            lam = 1.0 / self.C\n",
        "        elif self.penalty in [\"none\", None]:\n",
        "            lam = 0.0\n",
        "        else:\n",
        "            raise ValueError(\"поддерживаются только penalty='l2' или 'none'\")\n",
        "\n",
        "        for _ in range(self.n_iter):\n",
        "            z = X @ self.w_ + self.b_\n",
        "            p = self._sigmoid(z)\n",
        "            error = (p - y_bin) * sample_weight\n",
        "            grad_w = X.T @ error / n_samples + lam * self.w_\n",
        "            grad_b = error.mean()\n",
        "            self.w_ -= self.lr * grad_w\n",
        "            self.b_ -= self.lr * grad_b\n",
        "\n",
        "        z_train = X @ self.w_ + self.b_\n",
        "        p_train = self._sigmoid(z_train)\n",
        "\n",
        "        best_thr = 0.5\n",
        "        best_f1 = -1.0\n",
        "        for thr in np.linspace(0.1, 0.9, 17):\n",
        "            y_pred_thr = (p_train >= thr).astype(int)\n",
        "            f1 = f1_score(y_bin, y_pred_thr)\n",
        "            if f1 > best_f1:\n",
        "                best_f1 = f1\n",
        "                best_thr = thr\n",
        "\n",
        "        self.threshold_ = best_thr\n",
        "        return self\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        X = check_array(X, accept_sparse=False, dtype=float)\n",
        "        z = X @ self.w_ + self.b_\n",
        "        p1 = self._sigmoid(z)\n",
        "        p0 = 1.0 - p1\n",
        "        return np.vstack([p0, p1]).T\n",
        "\n",
        "    def predict(self, X):\n",
        "        proba = self.predict_proba(X)\n",
        "        y_bin_pred = (proba[:, 1] >= self.threshold_).astype(int)\n",
        "        return self.classes_[y_bin_pred]"
      ],
      "metadata": {
        "id": "nw2AvCQpCoJY"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Бейзлайн собственной реализации  \n",
        "Сначала раскладываю строковые поля Genres и Studios в списки, считаю частоты и выбираю top-10 самых популярных жанров и студий. Для них создаю бинарные признаки вида genre_X и studio_Y, которые показывают наличие соответствующего тега у тайтла. Далее формирую набор числовых признаков (Episodes + бинарные жанры и студии) и категориальных (Source, Type, Released_Season, Demographic), собираю матрицу признаков X и целевую переменную hit, и делю данные на обучающую и тестовую выборки со стратификацией по классу. Через ColumnTransformer масштабирую числовые признаки и one-hot кодирую категориальные, после чего в пайплайне обучаю свою MyLogisticRegression с L2-регуляризацией"
      ],
      "metadata": {
        "id": "EZnlEERH9mb5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "У sklearn-модели выше accuracy (≈0.77 против ≈0.65) и ROC-AUC (≈0.71 против ≈0.66), то есть она в среднем лучше ранжирует объекты по вероятности класса hit и реже ошибается, если смотреть на долю верных ответов  \n",
        "Однако моя реализация даёт гораздо более высокий F1 по классу hit (≈0.46 против ≈0.26) за счёт другого баланса precision/recall  \n",
        "sklearn-модель сильно осторожничает и почти всегда предсказывает класс 0 (recall по hit ≈0.17)  \n",
        "Моя модель, благодаря подбору порога по F1, чаще предсказывает класс 1 (recall по hit ≈0.60), жертвуя точностью (precision падает с ≈0.63 до ≈0.37)  \n",
        "В результате кастомная модель хуже по общей точности и ROC-AUC, но лучше решает задачу “находить как можно больше успешных тайтлов” и даёт более сбалансированные метрики для редкого класса hit."
      ],
      "metadata": {
        "id": "r5GXgRCuNBkR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Genres_l\"] = df[\"Genres\"].apply(lambda x: [i.strip() for i in str(x).split(\",\") if i.strip() != \"\"])\n",
        "genre_count = Counter()\n",
        "\n",
        "for g in df[\"Genres_l\"]:\n",
        "    genre_count.update(g)\n",
        "\n",
        "top_g = [i for i, _ in genre_count.most_common(10)]\n",
        "\n",
        "for g in top_g:\n",
        "    col_name = f\"genre_{g}\"\n",
        "    df[col_name] = df[\"Genres_l\"].apply(lambda lst: int(g in lst))\n",
        "\n",
        "g_cols = [f\"genre_{g}\" for g in top_g]\n",
        "df[g_cols].head()\n",
        "\n",
        "df[\"Studios_l\"] = df[\"Studios\"].apply(lambda x: [i.strip() for i in str(x).split(\",\") if i.strip() != \"\"])\n",
        "studio_count = Counter()\n",
        "for s in df[\"Studios_l\"]:\n",
        "  for st in s:\n",
        "    clean_s = st.strip()\n",
        "    if \"add some\" in clean_s.lower(): continue\n",
        "    studio_count[clean_s] += 1\n",
        "\n",
        "top_s = [i for i, _ in studio_count.most_common(10)]\n",
        "\n",
        "for s in top_s:\n",
        "    col_name = f\"studio_{s}\"\n",
        "    df[col_name] = df[\"Studios_l\"].apply(lambda lst: int(s in lst))\n",
        "\n",
        "studio_cols = [f\"studio_{s}\" for s in top_s]\n",
        "\n",
        "num = [\"Episodes\"] + g_cols + studio_cols\n",
        "categ = [\"Source\", \"Type\", \"Released_Season\", \"Demographic\"]\n",
        "feature = num + categ\n",
        "\n",
        "X = df[feature]\n",
        "y = df[\"hit\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42,stratify=y)\n",
        "\n",
        "pred = ColumnTransformer(transformers=[(\"num\", StandardScaler(),num),(\"categ\", OneHotEncoder(handle_unknown=\"ignore\"), categ)])\n",
        "\n",
        "log_base = Pipeline(steps=[\n",
        "    (\"pred\", pred),\n",
        "    (\"classifier\", MyLogisticRegression(\n",
        "        lr=0.1,\n",
        "        n_iter=1000,\n",
        "        penalty=\"l2\",\n",
        "        C=1.0,\n",
        "        class_weight=None,\n",
        "        random_state=42\n",
        "    ))\n",
        "])\n",
        "\n",
        "log_base.fit(X_train, y_train)\n",
        "\n",
        "y_pred_log = log_base.predict(X_test)\n",
        "y_proba_log = log_base.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"бейзлайн\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_log))\n",
        "print(\"F1-score:\", f1_score(y_test, y_pred_log))\n",
        "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba_log))\n",
        "print(classification_report(y_test, y_pred_log))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWw76BtRCqb9",
        "outputId": "ccb198ce-5b70-4c8b-cc81-6181101b2b2d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "бейзлайн\n",
            "Accuracy: 0.6481327800829876\n",
            "F1-score: 0.45918367346938777\n",
            "ROC-AUC: 0.6638394461434659\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.67      0.74       903\n",
            "           1       0.37      0.60      0.46       302\n",
            "\n",
            "    accuracy                           0.65      1205\n",
            "   macro avg       0.60      0.63      0.60      1205\n",
            "weighted avg       0.72      0.65      0.67      1205\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1 гипотеза"
      ],
      "metadata": {
        "id": "YEYY5mZqBqsM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "лучший набор оказался: C = 10, penalty = 'l2', class_weight = None. То есть модели выгоднее слабее регуляризоваться (большой C) и не вводить явный баланс классов - дисбаланс по hit мы уже частично компенсируем обучением и подбором порога  \n",
        "По сравнению с собственным бейзлайном гипотеза 1 даёт небольшое, но стабильное улучшение всех метрик: accuracy выросла до ≈ 0.652, F1 до ≈ 0.466, ROC-AUC до ≈ 0.682  \n",
        "То есть модель стала чуть лучше разделять классы по вероятностям и чуть лучше находить хиты: recall по классу 1 вырос до ≈ 0.61, precision до ≈ 0.38, F1 стало выше  \n",
        "Если сравнивать с логистической регрессией из sklearn со 2-й гипотезы, то качество очень близко: чуть больший F1 на классе hit (≈ 0.466 против ≈ 0.462), но проигрывает по Accuracy и ROC-AUC (≈ 0.652 / 0.682 против ≈ 0.666 / 0.701 у sklearn)."
      ],
      "metadata": {
        "id": "5pwMudZwV9aJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_log_clf1 = Pipeline(steps=[\n",
        "    (\"pred\", pred),\n",
        "    (\"classifier\", MyLogisticRegression(\n",
        "        lr=0.1,\n",
        "        n_iter=1000,\n",
        "        penalty=\"l2\",\n",
        "        C=1.0,\n",
        "        class_weight=None,\n",
        "        random_state=42\n",
        "    ))\n",
        "])\n",
        "\n",
        "param_grid_my1 = {\n",
        "    \"classifier__penalty\": [\"l2\"],\n",
        "    \"classifier__C\": [0.01, 0.1, 1.0, 3.0, 10.0],\n",
        "    \"classifier__class_weight\": [None, \"balanced\"],\n",
        "}\n",
        "\n",
        "grid_my1 = GridSearchCV(\n",
        "    estimator=my_log_clf1,\n",
        "    param_grid=param_grid_my1,\n",
        "    scoring=\"f1\",\n",
        "    cv=3,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid_my1.fit(X_train, y_train)\n",
        "\n",
        "print(\"Лучшие параметры:\", grid_my1.best_params_)\n",
        "print(\"Лучший F1 на CV:\", grid_my1.best_score_)\n",
        "\n",
        "best_my_log1 = grid_my1.best_estimator_\n",
        "\n",
        "y_pred_my1 = best_my_log1.predict(X_test)\n",
        "y_proba_my1 = best_my_log1.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"\\nгипотеза 1\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_my1))\n",
        "print(\"F1-score:\", f1_score(y_test, y_pred_my1))\n",
        "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba_my1))\n",
        "print(classification_report(y_test, y_pred_my1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AT3DNl6A3-q9",
        "outputId": "6aa8127b-084b-458e-a465-919fdb409dc5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лучшие параметры: {'classifier__C': 10.0, 'classifier__class_weight': None, 'classifier__penalty': 'l2'}\n",
            "Лучший F1 на CV: 0.47077361322449973\n",
            "\n",
            "гипотеза 1\n",
            "Accuracy: 0.6522821576763486\n",
            "F1-score: 0.4662420382165605\n",
            "ROC-AUC: 0.6819761941431431\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.67      0.74       903\n",
            "           1       0.38      0.61      0.47       302\n",
            "\n",
            "    accuracy                           0.65      1205\n",
            "   macro avg       0.61      0.64      0.60      1205\n",
            "weighted avg       0.72      0.65      0.67      1205\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2 гипотеза"
      ],
      "metadata": {
        "id": "SNfCo4B8Bvgy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GridSearch снова выбирает C = 10 и без явного взвешивания классов (class_weight=None), то есть модели выгодно слабое L2-наказание и обучение на исходном дисбалансе  \n",
        "По сравнению с бейзлайном метрики немного улучшаются: Accuracy растёт до ≈ 0.654, F1 до ≈ 0.47, ROC-AUC до ≈ 0.678. Модель по-прежнему даёт recall по классу hit ≈ 0.61 при precision ≈ 0.38, но F1 становится чуть выше, чем в гипотезе 1  \n",
        "В сравнении со 2-й гипотезой sklearn собственная реализация снова немного выигрывает в F1 по редкому классу hit, но уступает по общей точности и AUC. То есть кастомная модель остаётся чуть более агрессивной по отношению к классу 1 и ориентирована на максимизацию F1, а не на глобальную точность"
      ],
      "metadata": {
        "id": "Ic3vmjVlXL5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_log_clf2 = Pipeline(steps=[\n",
        "    (\"pred\", pred2),\n",
        "    (\"classifier\", MyLogisticRegression(\n",
        "        lr=0.1,\n",
        "        n_iter=1000,\n",
        "        penalty=\"l2\",\n",
        "        C=1.0,\n",
        "        class_weight=None,\n",
        "        random_state=42\n",
        "    ))\n",
        "])\n",
        "\n",
        "param_grid_my2 = {\n",
        "    \"classifier__penalty\": [\"l2\"],\n",
        "    \"classifier__C\": [0.01, 0.1, 1.0, 3.0, 10.0],\n",
        "    \"classifier__class_weight\": [None, \"balanced\"],\n",
        "}\n",
        "\n",
        "grid_my2 = GridSearchCV(\n",
        "    estimator=my_log_clf2,\n",
        "    param_grid=param_grid_my2,\n",
        "    scoring=\"f1\",\n",
        "    cv=3,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid_my2.fit(X2_train, y2_train)\n",
        "\n",
        "print(\"Лучшие параметры:\", grid_my2.best_params_)\n",
        "print(\"Лучший F1 на CV:\", grid_my2.best_score_)\n",
        "\n",
        "best_my_log2 = grid_my2.best_estimator_\n",
        "\n",
        "y_pred_my2 = best_my_log2.predict(X2_test)\n",
        "y_proba_my2 = best_my_log2.predict_proba(X2_test)[:, 1]\n",
        "\n",
        "print(\"\\nгипотеза 2\")\n",
        "print(\"Accuracy:\", accuracy_score(y2_test, y_pred_my2))\n",
        "print(\"F1-score:\", f1_score(y2_test, y_pred_my2))\n",
        "print(\"ROC-AUC:\", roc_auc_score(y2_test, y_proba_my2))\n",
        "print()\n",
        "print(classification_report(y2_test, y_pred_my2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZTZv-yS5Tq-",
        "outputId": "7fa3aa36-94a2-47af-be81-8f8cc36bc3ea"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лучшие параметры: {'classifier__C': 10.0, 'classifier__class_weight': None, 'classifier__penalty': 'l2'}\n",
            "Лучший F1 на CV: 0.47214686548019885\n",
            "\n",
            "гипотеза 2\n",
            "Accuracy: 0.653941908713693\n",
            "F1-score: 0.4701397712833545\n",
            "ROC-AUC: 0.6778655401788007\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.67      0.74       903\n",
            "           1       0.38      0.61      0.47       302\n",
            "\n",
            "    accuracy                           0.65      1205\n",
            "   macro avg       0.61      0.64      0.61      1205\n",
            "weighted avg       0.72      0.65      0.67      1205\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3 гипотеза"
      ],
      "metadata": {
        "id": "zJfpRsaWBxIT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GridSearch снова выбирает C = 10 и class_weight=None, а качество на тесте практически совпадает с гипотезой 1: Accuracy ≈ 0.65, F1 ≈ 0.47, ROC-AUC ≈ 0.682. Уточнение жанров/студий за счёт расширения до top-20 заметного прироста метрик не даёт - модель по-прежнему остаётся более чувствительной к классу hit (recall ≈ 0.61 при сравнительно низком precision ≈ 0.38), но баланс качество/сложность признаков почти не меняется"
      ],
      "metadata": {
        "id": "Z5pCEO4fXmIW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_log_clf3 = Pipeline(steps=[\n",
        "    (\"pred\", pred),\n",
        "    (\"classifier\", MyLogisticRegression(\n",
        "        lr=0.1,\n",
        "        n_iter=1000,\n",
        "        penalty=\"l2\",\n",
        "        C=1.0,\n",
        "        class_weight=None,\n",
        "        random_state=42\n",
        "    ))\n",
        "])\n",
        "\n",
        "param_grid_my3 = {\n",
        "    \"classifier__penalty\": [\"l2\"],\n",
        "    \"classifier__C\": [0.01, 0.1, 1.0, 3.0, 10.0],\n",
        "    \"classifier__class_weight\": [None, \"balanced\"],\n",
        "}\n",
        "\n",
        "grid_my3 = GridSearchCV(\n",
        "    estimator=my_log_clf3,\n",
        "    param_grid=param_grid_my3,\n",
        "    scoring=\"f1\",\n",
        "    cv=3,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid_my3.fit(X_train, y_train)\n",
        "\n",
        "print(\"Лучшие параметры:\", grid_my3.best_params_)\n",
        "print(\"Лучший F1 на CV:\", grid_my3.best_score_)\n",
        "\n",
        "best_my_log3 = grid_my3.best_estimator_\n",
        "\n",
        "y_pred_my3 = best_my_log3.predict(X_test)\n",
        "y_proba_my3 = best_my_log3.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"\\ntop-20 жанров/студий\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_my3))\n",
        "print(\"F1-score:\", f1_score(y_test, y_pred_my3))\n",
        "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba_my3))\n",
        "print(\"\\nОтчёт по классам:\")\n",
        "print(classification_report(y_test, y_pred_my3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FvsvJ8r5aBg",
        "outputId": "daaeb99c-956a-4412-b166-75b3dd857e41"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лучшие параметры: {'classifier__C': 10.0, 'classifier__class_weight': None, 'classifier__penalty': 'l2'}\n",
            "Лучший F1 на CV: 0.47077361322449973\n",
            "\n",
            "top-20 жанров/студий\n",
            "Accuracy: 0.6522821576763486\n",
            "F1-score: 0.4662420382165605\n",
            "ROC-AUC: 0.6819761941431431\n",
            "\n",
            "Отчёт по классам:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.67      0.74       903\n",
            "           1       0.38      0.61      0.47       302\n",
            "\n",
            "    accuracy                           0.65      1205\n",
            "   macro avg       0.61      0.64      0.60      1205\n",
            "weighted avg       0.72      0.65      0.67      1205\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Простой бейзлайн из sklearn даёт высокую accuracy за счёт перекоса в сторону неуспешного класса, но почти не видит хиты. После подбора гиперпараметров и учета дисбаланса классов удалось заметно поднять F1 по классу hit и recall, пожертвовав частью общей точности. Добавление логарифма по числу эпизодов и расширение набора бинарных признаков до top-20 жанров и студий дало лишь небольшие, косметические улучшения, без качественного скачка. Собственная реализация логистической регрессии воспроизводит те же тенденции и по метрикам ведет себя близко к библиотечной версии: где-то чуть выигрывает в F1 по редкому классу, где-то немного уступает по accuracy и ROC-AUC. В целом можно считать, что модель работает адекватно, а ключевую роль снова играет не столько выбор алгоритма, сколько грамотная постановка таргета, обработка дисбаланса и аккуратная работа с признаками"
      ],
      "metadata": {
        "id": "ziwHULRoYJ_N"
      }
    }
  ]
}