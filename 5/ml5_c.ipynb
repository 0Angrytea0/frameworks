{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V5E1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jbCLttD_Ro8T"
      },
      "outputs": [],
      "source": [
        "#KGAT_746a8c48819a19cbaf8ca0048244831b"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opendatasets\n",
        "!pip install pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGZrj-I3RuSs",
        "outputId": "ad2c50c1-a1a9-44bf-a54a-8be627836bc0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from opendatasets) (4.67.1)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (from opendatasets) (1.7.4.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from opendatasets) (8.3.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (6.3.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2025.11.12)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (3.4.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (3.11)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (6.33.2)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (0.5.1)\n",
            "Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.22\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Скачиваем"
      ],
      "metadata": {
        "id": "0mi99tXgR98I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od\n",
        "od.download(\"https://www.kaggle.com/datasets/syahrulapriansyah2/myanimelist-2025\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_okFQBXQRvdu",
        "outputId": "9cc5c014-fce6-4486-d3e8-c848c25b5835"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: angrytea\n",
            "Your Kaggle Key: ··········\n",
            "Dataset URL: https://www.kaggle.com/datasets/syahrulapriansyah2/myanimelist-2025\n",
            "Downloading myanimelist-2025.zip to ./myanimelist-2025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.57M/9.57M [00:00<00:00, 2.33GB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Библиотеки"
      ],
      "metadata": {
        "id": "IA0QI30zR8un"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, classification_report\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin, RegressorMixin\n",
        "from sklearn.ensemble import GradientBoostingClassifier"
      ],
      "metadata": {
        "id": "1y1DN_GbRw3Y"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Открываем датасет  \n",
        "Удаляем строки, не имеющие в Members значения  \n",
        "Задаем условие успешности: тайтл успешный, если у него 75% и больше зрителей: 1 - аниме успешное (собрало много просмотров) 0 - не успешное  \n",
        "Для признаков возьмем Source, Type, Released_Season, Episodes, Genres, Studios, Demographic  \n",
        "Пропуски по эпизодам заменяем медианой, по категориальным признакам на Unknown, жанрам и студиям поставим пустые строки  \n",
        "Создаем список жанров  \n",
        "Ищем самые популярные жанры и делаем для них колонки  \n",
        "Список студий делаем  \n",
        "Ищем популярные студии, не учитывая 'add some'  \n",
        "Задаем колонки  \n",
        "Собираем матрицу X из фич и назначаем целевую переменную успешности y  \n",
        "Делим данные на train и test  \n",
        "Числовые и бинарные признаки будем масштабировать, а для категориальных используем one-hot encoding  "
      ],
      "metadata": {
        "id": "fexk5feOR7vc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option(\"display.max_columns\", None)\n",
        "df = pd.read_csv(\"myanimelist-2025/mal_anime.csv\")\n",
        "df[\"Members\"] = pd.to_numeric(df[\"Members\"], errors=\"coerce\")\n",
        "df = df.dropna(subset=[\"Members\"])\n",
        "th = df[\"Members\"].quantile(0.75)\n",
        "\n",
        "df[\"hit\"] = (df[\"Members\"] >= th).astype(int)\n",
        "df[\"Episodes\"] = pd.to_numeric(df[\"Episodes\"], errors=\"coerce\")\n",
        "m_episodes = df[\"Episodes\"].median()\n",
        "df[\"Episodes\"] = df[\"Episodes\"].fillna(m_episodes)\n",
        "\n",
        "for col in [\"Source\", \"Type\", \"Released_Season\", \"Demographic\"]:\n",
        "    df[col] = df[col].fillna(\"Unknown\")\n",
        "\n",
        "for col in [\"Genres\", \"Studios\"]: df[col] = df[col].fillna(\"\")\n",
        "\n",
        "df[\"Genres_l\"] = df[\"Genres\"].apply(lambda x: [i.strip() for i in str(x).split(\",\") if i.strip() != \"\"])\n",
        "genre_count = Counter()\n",
        "\n",
        "for g in df[\"Genres_l\"]:\n",
        "    genre_count.update(g)\n",
        "\n",
        "top_g = [i for i, _ in genre_count.most_common(10)]\n",
        "\n",
        "for g in top_g:\n",
        "    col_name = f\"genre_{g}\"\n",
        "    df[col_name] = df[\"Genres_l\"].apply(lambda lst: int(g in lst))\n",
        "\n",
        "g_cols = [f\"genre_{g}\" for g in top_g]\n",
        "df[\"Studios_l\"] = df[\"Studios\"].apply(lambda x: [i.strip() for i in str(x).split(\",\") if i.strip() != \"\"])\n",
        "\n",
        "studio_count = Counter()\n",
        "for s in df[\"Studios_l\"]:\n",
        "  for st in s:\n",
        "    clean_s = st.strip()\n",
        "    if \"add some\" in clean_s.lower(): continue\n",
        "    studio_count[clean_s] += 1\n",
        "\n",
        "top_s = [i for i, _ in studio_count.most_common(10)]\n",
        "for s in top_s:\n",
        "    col_name = f\"studio_{s}\"\n",
        "    df[col_name] = df[\"Studios_l\"].apply(lambda lst: int(s in lst))\n",
        "\n",
        "studio_cols = [f\"studio_{s}\" for s in top_s]\n",
        "\n",
        "num = [\"Episodes\"] + g_cols + studio_cols\n",
        "categ = [\"Source\", \"Type\", \"Released_Season\", \"Demographic\"]\n",
        "feature = num + categ\n",
        "\n",
        "X = df[feature]\n",
        "y = df[\"hit\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42,stratify=y)\n",
        "pred = ColumnTransformer(transformers=[\n",
        "    (\"num\", StandardScaler(),num),\n",
        "    (\"categ\", OneHotEncoder(handle_unknown=\"ignore\"), categ)\n",
        "])"
      ],
      "metadata": {
        "id": "N5qeLxWMR3K3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Бейзлайн"
      ],
      "metadata": {
        "id": "L65wPPV1TJU7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Точность получается 0.76, но F1-мера по целевому классу «успешное аниме» заметно ниже (0.24), что говорит о слабом улавливании именно редкого положительного класса. ROC-AUC около 0.73 показывает, что модель в среднем неплохо ранжирует объекты по вероятности успеха, но в точке принятия решения (0.5) серьёзно перекошена в сторону предсказаний класса 0."
      ],
      "metadata": {
        "id": "rkkIxCbBijTG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gb_base = Pipeline(steps=[\n",
        "    (\"pred\", pred),\n",
        "    (\"clf\", GradientBoostingClassifier(\n",
        "        random_state=42\n",
        "    ))\n",
        "])\n",
        "\n",
        "gb_base.fit(X_train, y_train)\n",
        "\n",
        "y_pred_gb = gb_base.predict(X_test)\n",
        "y_proba_gb = gb_base.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"Безйлайн\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_gb))\n",
        "print(\"F1-score:\", f1_score(y_test, y_pred_gb))\n",
        "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba_gb))\n",
        "print(classification_report(y_test, y_pred_gb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97wHjHSlTIzH",
        "outputId": "0737a44c-dd6c-474d-b5fc-adb1628ad5bb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Безйлайн\n",
            "Accuracy: 0.762655601659751\n",
            "F1-score: 0.2393617021276596\n",
            "ROC-AUC: 0.7352991866698936\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.97      0.86       903\n",
            "           1       0.61      0.15      0.24       302\n",
            "\n",
            "    accuracy                           0.76      1205\n",
            "   macro avg       0.69      0.56      0.55      1205\n",
            "weighted avg       0.73      0.76      0.70      1205\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1 гипотеза - качество можно улучшить, если подобрать количество базовых деревьев, learning_rate и глубину деревьев в бустинге. Здесь запускаю GridSearchCV по нескольким разумным значениям и оптимизирую F1 по классу hit"
      ],
      "metadata": {
        "id": "c_PiexHdTPnE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "На тесте точность остаётся примерно на уровне бейзлайна (0.76), но F1 растёт до 0.37 за счёт заметного увеличения recall и более сбалансированного качества между классами. ROC-AUC немного снижается относительно базовой модели (около 0.71 против 0.73), то есть общее качество ранжирования чуть хуже, но при выбранном пороге классификации модель лучше выделяет успешные тайтлы. Гипотеза подтверждается: за счёт настройки глубины и числа деревьев удалось ощутимо поднять F1 по целевому классу"
      ],
      "metadata": {
        "id": "9Jxw4UNliqyV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid_gb1 = {\n",
        "    \"clf__n_estimators\": [100, 200, 300],\n",
        "    \"clf__learning_rate\": [0.05, 0.1, 0.2],\n",
        "    \"clf__max_depth\": [2, 3, 4]\n",
        "}\n",
        "\n",
        "gb_clf1 = Pipeline(steps=[\n",
        "    (\"pred\", pred),\n",
        "    (\"clf\", GradientBoostingClassifier(\n",
        "        random_state=42\n",
        "    ))\n",
        "])\n",
        "\n",
        "gb_gs1 = GridSearchCV(\n",
        "    estimator=gb_clf1,\n",
        "    param_grid=param_grid_gb1,\n",
        "    scoring=\"f1\",\n",
        "    cv=3,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "gb_gs1.fit(X_train, y_train)\n",
        "\n",
        "print(\"Лучшие параметры:\", gb_gs1.best_params_)\n",
        "print(\"Лучший F1 на CV:\", gb_gs1.best_score_)\n",
        "\n",
        "best_gb1 = gb_gs1.best_estimator_\n",
        "y_pred_gb1 = best_gb1.predict(X_test)\n",
        "y_proba_gb1 = best_gb1.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"\\nГипотеза 1\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_gb1))\n",
        "print(\"F1-score:\", f1_score(y_test, y_pred_gb1))\n",
        "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba_gb1))\n",
        "print(classification_report(y_test, y_pred_gb1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDkctG1UTPU7",
        "outputId": "f96defad-4ec2-4785-aeb2-235a67c90046"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лучшие параметры: {'clf__learning_rate': 0.2, 'clf__max_depth': 4, 'clf__n_estimators': 300}\n",
            "Лучший F1 на CV: 0.3658074559865983\n",
            "\n",
            "Гипотеза 1\n",
            "Accuracy: 0.7601659751037344\n",
            "F1-score: 0.3676148796498906\n",
            "ROC-AUC: 0.7113888216614229\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.92      0.85       903\n",
            "           1       0.54      0.28      0.37       302\n",
            "\n",
            "    accuracy                           0.76      1205\n",
            "   macro avg       0.67      0.60      0.61      1205\n",
            "weighted avg       0.73      0.76      0.73      1205\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2 гипотеза - число эпизодов сильно варьируется и может вести себя как длинный хвост, поэтому логарифмирование Episodes (log(1 + Episodes)) сделает распределение более сглаженным и может помочь бустингу чуть лучше разделять классы"
      ],
      "metadata": {
        "id": "fAC4CwCaTrpy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Получившиеся лучшие параметры практически совпадают с гипотезой 1, а итоговые метрики на тесте (Accuracy, F1, ROC-AUC) фактически идентичны: лог-преобразование числа эпизодов не даёт дополнительного выигрыша по сравнению с уже настроенной моделью. Это значит, что для градиентного бустинга информация о числе эпизодов уже достаточно хорошо «отрабатывается» деревьями, и простое логарифмирование не даёт заметного эффекта. Гипотеза по сути не подтверждается — повышение качества по сравнению с гипотезой 1 отсутствует"
      ],
      "metadata": {
        "id": "MyHcPSfWiwNK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df.copy()\n",
        "df2[\"log_Episodes\"] = np.log1p(df2[\"Episodes\"])\n",
        "\n",
        "num2 = [\"log_Episodes\"] + g_cols + studio_cols\n",
        "categ2 = [\"Source\", \"Type\", \"Released_Season\", \"Demographic\"]\n",
        "feature2 = num2 + categ2\n",
        "\n",
        "X2 = df2[feature2]\n",
        "y2 = df2[\"hit\"]\n",
        "\n",
        "X2_train, X2_test, y2_train, y2_test = train_test_split(\n",
        "    X2, y2,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y2\n",
        ")\n",
        "\n",
        "pred2 = ColumnTransformer(transformers=[\n",
        "    (\"num2\", StandardScaler(), num2),\n",
        "    (\"categ\", OneHotEncoder(handle_unknown=\"ignore\"), categ2),\n",
        "])\n",
        "\n",
        "gb_clf2 = Pipeline(steps=[\n",
        "    (\"pred\", pred2),\n",
        "    (\"clf\", GradientBoostingClassifier(\n",
        "        random_state=42\n",
        "    ))\n",
        "])\n",
        "\n",
        "gb_gs2 = GridSearchCV(\n",
        "    estimator=gb_clf2,\n",
        "    param_grid=param_grid_gb1,\n",
        "    scoring=\"f1\",\n",
        "    cv=3,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "gb_gs2.fit(X2_train, y2_train)\n",
        "\n",
        "print(\"Лучшие параметры:\", gb_gs2.best_params_)\n",
        "print(\"Лучший F1 на CV:\", gb_gs2.best_score_)\n",
        "\n",
        "best_gb2 = gb_gs2.best_estimator_\n",
        "y_pred_gb2 = best_gb2.predict(X2_test)\n",
        "y_proba_gb2 = best_gb2.predict_proba(X2_test)[:, 1]\n",
        "\n",
        "print(\"\\nGradientBoosting + log(Episodes)\")\n",
        "print(\"Accuracy:\", accuracy_score(y2_test, y_pred_gb2))\n",
        "print(\"F1-score:\", f1_score(y2_test, y_pred_gb2))\n",
        "print(\"ROC-AUC:\", roc_auc_score(y2_test, y_proba_gb2))\n",
        "print(classification_report(y2_test, y_pred_gb2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kiHtZO6TuRJ",
        "outputId": "fe737a8f-99a9-4cec-dd7a-e6b9cf7b1716"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лучшие параметры: {'clf__learning_rate': 0.2, 'clf__max_depth': 4, 'clf__n_estimators': 300}\n",
            "Лучший F1 на CV: 0.3647641591686536\n",
            "\n",
            "GradientBoosting + log(Episodes)\n",
            "Accuracy: 0.7601659751037344\n",
            "F1-score: 0.3676148796498906\n",
            "ROC-AUC: 0.710589425975226\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.92      0.85       903\n",
            "           1       0.54      0.28      0.37       302\n",
            "\n",
            "    accuracy                           0.76      1205\n",
            "   macro avg       0.67      0.60      0.61      1205\n",
            "weighted avg       0.73      0.76      0.73      1205\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3 гипотеза - расширить топ до 20"
      ],
      "metadata": {
        "id": "nRD9c8eaT5lB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "На тесте точность немного снижается (0.75 против 0.76 в гипотезе 1), F1-мера (0.34) также чуть хуже, чем у лучшей модели из гипотезы 1, но всё ещё заметно выше исходного бейзлайна. ROC-AUC опускается до 0.706, что тоже хуже как базовой настройки, так и модели из гипотезы 1. В итоге расширение признакового пространства до top-20 жанров/студий не приносит дополнительного выигрыша — модель становится чуть сложнее, но по качеству слегка уступает лучшему варианту из гипотезы 1"
      ],
      "metadata": {
        "id": "zQgxijLoi5A0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "genre_count_full = Counter()\n",
        "for g_list in df[\"Genres_l\"]:\n",
        "    genre_count_full.update(g_list)\n",
        "\n",
        "top_g20 = [i for i, _ in genre_count_full.most_common(20)]\n",
        "\n",
        "for g in top_g20:\n",
        "    col_name = f\"genre20_{g}\"\n",
        "    df[col_name] = df[\"Genres_l\"].apply(lambda lst: int(g in lst))\n",
        "\n",
        "g_cols20 = [f\"genre20_{g}\" for g in top_g20]\n",
        "\n",
        "studio_count_full = Counter()\n",
        "for s_list in df[\"Studios_l\"]:\n",
        "    for st in s_list:\n",
        "        clean_s = st.strip()\n",
        "        if \"add some\" in clean_s.lower():\n",
        "            continue\n",
        "        studio_count_full[clean_s] += 1\n",
        "\n",
        "top_s20 = [i for i, _ in studio_count_full.most_common(20)]\n",
        "\n",
        "for s in top_s20:\n",
        "    col_name = f\"studio20_{s}\"\n",
        "    df[col_name] = df[\"Studios_l\"].apply(lambda lst: int(s in lst))\n",
        "\n",
        "studio_cols20 = [f\"studio20_{s}\" for s in top_s20]\n",
        "\n",
        "num3 = [\"Episodes\"] + g_cols20 + studio_cols20\n",
        "categ3 = [\"Source\", \"Type\", \"Released_Season\", \"Demographic\"]\n",
        "feature3 = num3 + categ3\n",
        "\n",
        "X3 = df[feature3]\n",
        "y3 = df[\"hit\"]\n",
        "\n",
        "X3_train, X3_test, y3_train, y3_test = train_test_split(\n",
        "    X3, y3,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y3\n",
        ")\n",
        "\n",
        "pred3 = ColumnTransformer(transformers=[\n",
        "    (\"num3\", StandardScaler(), num3),\n",
        "    (\"categ\", OneHotEncoder(handle_unknown=\"ignore\"), categ3),\n",
        "])\n",
        "\n",
        "gb_clf3 = Pipeline(steps=[\n",
        "    (\"pred\", pred3),\n",
        "    (\"clf\", GradientBoostingClassifier(\n",
        "        random_state=42\n",
        "    ))\n",
        "])\n",
        "\n",
        "gb_gs3 = GridSearchCV(\n",
        "    estimator=gb_clf3,\n",
        "    param_grid=param_grid_gb1,\n",
        "    scoring=\"f1\",\n",
        "    cv=3,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "gb_gs3.fit(X3_train, y3_train)\n",
        "\n",
        "print(\"Лучшие параметры:\", gb_gs3.best_params_)\n",
        "print(\"Лучший F1 на CV:\", gb_gs3.best_score_)\n",
        "\n",
        "best_gb3 = gb_gs3.best_estimator_\n",
        "y_pred_gb3 = best_gb3.predict(X3_test)\n",
        "y_proba_gb3 = best_gb3.predict_proba(X3_test)[:, 1]\n",
        "\n",
        "print(\"\\nGradientBoosting + top-20 жанров/студий\")\n",
        "print(\"Accuracy:\", accuracy_score(y3_test, y_pred_gb3))\n",
        "print(\"F1-score:\", f1_score(y3_test, y_pred_gb3))\n",
        "print(\"ROC-AUC:\", roc_auc_score(y3_test, y_proba_gb3))\n",
        "print(classification_report(y3_test, y_pred_gb3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlgE7A6QT78H",
        "outputId": "d21e5e2b-1e16-4e3f-fcaf-53748e57584f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лучшие параметры: {'clf__learning_rate': 0.2, 'clf__max_depth': 4, 'clf__n_estimators': 300}\n",
            "Лучший F1 на CV: 0.3812519318027274\n",
            "\n",
            "GradientBoosting + top-20 жанров/студий\n",
            "Accuracy: 0.7477178423236515\n",
            "F1-score: 0.341991341991342\n",
            "ROC-AUC: 0.7056775428483422\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.91      0.84       903\n",
            "           1       0.49      0.26      0.34       302\n",
            "\n",
            "    accuracy                           0.75      1205\n",
            "   macro avg       0.64      0.59      0.59      1205\n",
            "weighted avg       0.71      0.75      0.72      1205\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Собственная реализация"
      ],
      "metadata": {
        "id": "_HKmF4SvU3hr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сначала описываю MyDecisionTreeRegressor - простое регрессионное дерево, которое на каждом шаге перебирает признаки и пороги, выбирает разбиение, минимизирующее MSE, и в листьях хранит среднее значение целевой переменной. Это дерево я использую как базовый алгоритм в бустинге.\n",
        "Далее реализую MyGradientBoostingClassifier  \n",
        "1) перевожу таргет в 0/1\n",
        "2) начинаю с константного предсказания (средняя вероятность класса 1)\n",
        "3) на каждой итерации считаю остатки между правильными метками и текущими предсказаниями, обучаю новое регрессионное дерево на этих остатках и добавляю его вклад к скору с шагом learning_rate\n",
        "4) для предсказаний по новым объектам последовательно суммирую вклад всех деревьев и обрезаю результат в диапазон [0, 1], после чего трактую его как вероятность класса 1 и порогом 0.5 перевожу в метки классов\n"
      ],
      "metadata": {
        "id": "TKIRJfWAko_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDecisionTreeRegressor(BaseEstimator, RegressorMixin):\n",
        "    def __init__(\n",
        "        self,\n",
        "        max_depth=None,\n",
        "        min_samples_split=2,\n",
        "        min_samples_leaf=1,\n",
        "        random_state=None\n",
        "    ):\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.min_samples_leaf = min_samples_leaf\n",
        "        self.random_state = random_state\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        X = np.asarray(X)\n",
        "        y = np.asarray(y)\n",
        "        n_samples, n_features = X.shape\n",
        "\n",
        "        rng = np.random.RandomState(self.random_state)\n",
        "        self.n_features_ = n_features\n",
        "        self.tree_ = []\n",
        "\n",
        "        def mse(values):\n",
        "            if values.size == 0:\n",
        "                return 0.0\n",
        "            mean = values.mean()\n",
        "            return np.mean((values - mean) ** 2)\n",
        "\n",
        "        def best_split(X_node, y_node, depth):\n",
        "            n_samples_node, n_features_node = X_node.shape\n",
        "            if n_samples_node < self.min_samples_split:\n",
        "                return None, None, None, None\n",
        "            if self.max_depth is not None and depth >= self.max_depth:\n",
        "                return None, None, None, None\n",
        "\n",
        "            best_feature = None\n",
        "            best_threshold = None\n",
        "            best_score = np.inf\n",
        "            best_left_idx = None\n",
        "            best_right_idx = None\n",
        "\n",
        "            for feature in range(n_features_node):\n",
        "                values = X_node[:, feature]\n",
        "                thresholds = np.unique(values)\n",
        "                for thr in thresholds:\n",
        "                    left_idx = values <= thr\n",
        "                    right_idx = values > thr\n",
        "                    if left_idx.sum() < self.min_samples_leaf or right_idx.sum() < self.min_samples_leaf:\n",
        "                        continue\n",
        "                    mse_left = mse(y_node[left_idx])\n",
        "                    mse_right = mse(y_node[right_idx])\n",
        "                    score = (left_idx.sum() * mse_left + right_idx.sum() * mse_right) / n_samples_node\n",
        "                    if score < best_score:\n",
        "                        best_score = score\n",
        "                        best_feature = feature\n",
        "                        best_threshold = thr\n",
        "                        best_left_idx = left_idx\n",
        "                        best_right_idx = right_idx\n",
        "\n",
        "            if best_feature is None:\n",
        "                return None, None, None, None\n",
        "            return best_feature, best_threshold, best_left_idx, best_right_idx\n",
        "\n",
        "        def build_tree(X_node, y_node, depth):\n",
        "            node = {}\n",
        "            node[\"value\"] = float(y_node.mean())\n",
        "\n",
        "            feature, threshold, left_idx, right_idx = best_split(X_node, y_node, depth)\n",
        "            if feature is None:\n",
        "                node[\"feature\"] = None\n",
        "                node[\"threshold\"] = None\n",
        "                node[\"left\"] = None\n",
        "                node[\"right\"] = None\n",
        "                return node\n",
        "\n",
        "            node[\"feature\"] = feature\n",
        "            node[\"threshold\"] = threshold\n",
        "            node[\"left\"] = build_tree(X_node[left_idx], y_node[left_idx], depth + 1)\n",
        "            node[\"right\"] = build_tree(X_node[right_idx], y_node[right_idx], depth + 1)\n",
        "            return node\n",
        "\n",
        "        self.tree_ = build_tree(X, y, depth=0)\n",
        "        return self\n",
        "\n",
        "    def _predict_one(self, x, node):\n",
        "        while node[\"feature\"] is not None:\n",
        "            if x[node[\"feature\"]] <= node[\"threshold\"]:\n",
        "                node = node[\"left\"]\n",
        "            else:\n",
        "                node = node[\"right\"]\n",
        "        return node[\"value\"]\n",
        "\n",
        "    def predict(self, X):\n",
        "        X = np.asarray(X)\n",
        "        n_samples = X.shape[0]\n",
        "        y_pred = np.zeros(n_samples, dtype=float)\n",
        "        for i in range(n_samples):\n",
        "            y_pred[i] = self._predict_one(X[i], self.tree_)\n",
        "        return y_pred\n",
        "\n",
        "class MyGradientBoostingClassifier(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(\n",
        "        self,\n",
        "        n_estimators=100,\n",
        "        learning_rate=0.1,\n",
        "        max_depth=3,\n",
        "        min_samples_split=2,\n",
        "        min_samples_leaf=1,\n",
        "        random_state=None\n",
        "    ):\n",
        "        self.n_estimators = n_estimators\n",
        "        self.learning_rate = learning_rate\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.min_samples_leaf = min_samples_leaf\n",
        "        self.random_state = random_state\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        X = np.asarray(X)\n",
        "        y = np.asarray(y)\n",
        "\n",
        "        self.classes_ = np.unique(y)\n",
        "        if self.classes_.shape[0] != 2:\n",
        "            raise ValueError(\"MyGradientBoostingClassifier поддерживает только бинарную классификацию\")\n",
        "\n",
        "        y_bin = (y == self.classes_[1]).astype(float)\n",
        "        n_samples = X.shape[0]\n",
        "\n",
        "        base_pred = np.full(n_samples, y_bin.mean())\n",
        "        self.base_pred_ = base_pred.mean()\n",
        "\n",
        "        self.trees_ = []\n",
        "\n",
        "        F = np.full(n_samples, self.base_pred_, dtype=float)\n",
        "\n",
        "        for m in range(self.n_estimators):\n",
        "            residual = y_bin - F\n",
        "\n",
        "            tree = MyDecisionTreeRegressor(\n",
        "                max_depth=self.max_depth,\n",
        "                min_samples_split=self.min_samples_split,\n",
        "                min_samples_leaf=self.min_samples_leaf\n",
        "            )\n",
        "            tree.fit(X, residual)\n",
        "            self.trees_.append(tree)\n",
        "\n",
        "            update = tree.predict(X)\n",
        "            F += self.learning_rate * update\n",
        "\n",
        "        return self\n",
        "\n",
        "    def _raw_predict(self, X):\n",
        "        X = np.asarray(X)\n",
        "        F = np.full(X.shape[0], self.base_pred_, dtype=float)\n",
        "        for tree in self.trees_:\n",
        "            F += self.learning_rate * tree.predict(X)\n",
        "        return F\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        F = self._raw_predict(X)\n",
        "        p1 = np.clip(F, 1e-5, 1 - 1e-5)\n",
        "        p0 = 1.0 - p1\n",
        "        return np.vstack([p0, p1]).T\n",
        "\n",
        "    def predict(self, X):\n",
        "        proba = self.predict_proba(X)\n",
        "        y_bin = (proba[:, 1] >= 0.5).astype(int)\n",
        "        return self.classes_[y_bin]"
      ],
      "metadata": {
        "id": "xytzUVRQU4-o"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Бйзлайн"
      ],
      "metadata": {
        "id": "icey2hb7U53_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_gb_base = Pipeline(steps=[\n",
        "    (\"pred\", pred),\n",
        "    (\"clf\", MyGradientBoostingClassifier(\n",
        "        n_estimators=100,\n",
        "        learning_rate=0.1,\n",
        "        max_depth=3,\n",
        "        min_samples_split=2,\n",
        "        min_samples_leaf=1,\n",
        "        random_state=42\n",
        "    ))\n",
        "])\n",
        "\n",
        "my_gb_base.fit(X_train, y_train)\n",
        "\n",
        "y_pred_my_gb = my_gb_base.predict(X_test)\n",
        "y_proba_my_gb = my_gb_base.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"Бейзлайн\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_my_gb))\n",
        "print(\"F1-score:\", f1_score(y_test, y_pred_my_gb))\n",
        "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba_my_gb))\n",
        "print(classification_report(y_test, y_pred_my_gb))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODsUP3pgU7bx",
        "outputId": "4bb7e9e3-fb57-4d81-fcf0-a3f93a1837d9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Бейзлайн\n",
            "Accuracy: 0.762655601659751\n",
            "F1-score: 0.23118279569892472\n",
            "ROC-AUC: 0.7336472244835098\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.97      0.86       903\n",
            "           1       0.61      0.14      0.23       302\n",
            "\n",
            "    accuracy                           0.76      1205\n",
            "   macro avg       0.69      0.56      0.55      1205\n",
            "weighted avg       0.73      0.76      0.70      1205\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1 гипотеза"
      ],
      "metadata": {
        "id": "cLHLjNO9U_6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid_my_gb1 = {\n",
        "    \"clf__n_estimators\": [100, 200, 300],\n",
        "    \"clf__learning_rate\": [0.05, 0.1, 0.2],\n",
        "    \"clf__max_depth\": [2, 3, 4]\n",
        "}\n",
        "\n",
        "my_gb_clf1 = Pipeline(steps=[\n",
        "    (\"pred\", pred),\n",
        "    (\"clf\", MyGradientBoostingClassifier(\n",
        "        n_estimators=100,\n",
        "        learning_rate=0.1,\n",
        "        max_depth=3,\n",
        "        min_samples_split=2,\n",
        "        min_samples_leaf=1,\n",
        "        random_state=42\n",
        "    ))\n",
        "])\n",
        "\n",
        "my_gb_gs1 = GridSearchCV(\n",
        "    estimator=my_gb_clf1,\n",
        "    param_grid=param_grid_my_gb1,\n",
        "    scoring=\"f1\",\n",
        "    cv=3,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "my_gb_gs1.fit(X_train, y_train)\n",
        "\n",
        "print(\"Лучшие параметры:\", my_gb_gs1.best_params_)\n",
        "print(\"Лучший F1 на CV:\", my_gb_gs1.best_score_)\n",
        "\n",
        "best_my_gb1 = my_gb_gs1.best_estimator_\n",
        "y_pred_my_gb1 = best_my_gb1.predict(X_test)\n",
        "y_proba_my_gb1 = best_my_gb1.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"\\nГипотеза 1\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_my_gb1))\n",
        "print(\"F1-score:\", f1_score(y_test, y_pred_my_gb1))\n",
        "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba_my_gb1))\n",
        "print(classification_report(y_test, y_pred_my_gb1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzKqlXynVA9w",
        "outputId": "d57c447b-2a0a-4dc7-c9da-19c1371a5ee6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лучшие параметры: {'clf__learning_rate': 0.2, 'clf__max_depth': 4, 'clf__n_estimators': 300}\n",
            "Лучший F1 на CV: 0.36529977068965763\n",
            "\n",
            "Гипотеза 1\n",
            "Accuracy: 0.7634854771784232\n",
            "F1-score: 0.3595505617977528\n",
            "ROC-AUC: 0.7188712386232792\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.93      0.85       903\n",
            "           1       0.56      0.26      0.36       302\n",
            "\n",
            "    accuracy                           0.76      1205\n",
            "   macro avg       0.68      0.60      0.61      1205\n",
            "weighted avg       0.73      0.76      0.73      1205\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2 гипотеза"
      ],
      "metadata": {
        "id": "Sg2NQS0qW96T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_gb_clf2 = Pipeline(steps=[\n",
        "    (\"pred\", pred2),\n",
        "    (\"clf\", MyGradientBoostingClassifier(\n",
        "        n_estimators=100,\n",
        "        learning_rate=0.1,\n",
        "        max_depth=3,\n",
        "        min_samples_split=2,\n",
        "        min_samples_leaf=1,\n",
        "        random_state=42\n",
        "    ))\n",
        "])\n",
        "\n",
        "my_gb_gs2 = GridSearchCV(\n",
        "    estimator=my_gb_clf2,\n",
        "    param_grid=param_grid_my_gb1,\n",
        "    scoring=\"f1\",\n",
        "    cv=3,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "my_gb_gs2.fit(X2_train, y2_train)\n",
        "\n",
        "print(\"Лучшие параметры:\", my_gb_gs2.best_params_)\n",
        "print(\"Лучший F1 на CV:\", my_gb_gs2.best_score_)\n",
        "\n",
        "best_my_gb2 = my_gb_gs2.best_estimator_\n",
        "y_pred_my_gb2 = best_my_gb2.predict(X2_test)\n",
        "y_proba_my_gb2 = best_my_gb2.predict_proba(X2_test)[:, 1]\n",
        "\n",
        "print(\"\\nMyGradientBoosting + log(Episodes)\")\n",
        "print(\"Accuracy:\", accuracy_score(y2_test, y_pred_my_gb2))\n",
        "print(\"F1-score:\", f1_score(y2_test, y_pred_my_gb2))\n",
        "print(\"ROC-AUC:\", roc_auc_score(y2_test, y_proba_my_gb2))\n",
        "print(classification_report(y2_test, y_pred_my_gb2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aApAhk5W-si",
        "outputId": "290e20b7-f50a-4dd6-ef8c-37a2d35c7f95"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лучшие параметры: {'clf__learning_rate': 0.2, 'clf__max_depth': 4, 'clf__n_estimators': 300}\n",
            "Лучший F1 на CV: 0.36529977068965763\n",
            "\n",
            "MyGradientBoosting + log(Episodes)\n",
            "Accuracy: 0.7634854771784232\n",
            "F1-score: 0.3595505617977528\n",
            "ROC-AUC: 0.7188712386232792\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.93      0.85       903\n",
            "           1       0.56      0.26      0.36       302\n",
            "\n",
            "    accuracy                           0.76      1205\n",
            "   macro avg       0.68      0.60      0.61      1205\n",
            "weighted avg       0.73      0.76      0.73      1205\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3 гипотеза"
      ],
      "metadata": {
        "id": "yAExMcUYXCK4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_gb_clf3 = Pipeline(steps=[\n",
        "    (\"pred\", pred3),\n",
        "    (\"clf\", MyGradientBoostingClassifier(\n",
        "        n_estimators=100,\n",
        "        learning_rate=0.1,\n",
        "        max_depth=3,\n",
        "        min_samples_split=2,\n",
        "        min_samples_leaf=1,\n",
        "        random_state=42\n",
        "    ))\n",
        "])\n",
        "\n",
        "my_gb_gs3 = GridSearchCV(\n",
        "    estimator=my_gb_clf3,\n",
        "    param_grid=param_grid_my_gb1,\n",
        "    scoring=\"f1\",\n",
        "    cv=3,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "my_gb_gs3.fit(X3_train, y3_train)\n",
        "\n",
        "print(\"Лучшие параметры:\", my_gb_gs3.best_params_)\n",
        "print(\"Лучший F1 на CV:\", my_gb_gs3.best_score_)\n",
        "\n",
        "best_my_gb3 = my_gb_gs3.best_estimator_\n",
        "y_pred_my_gb3 = best_my_gb3.predict(X3_test)\n",
        "y_proba_my_gb3 = best_my_gb3.predict_proba(X3_test)[:, 1]\n",
        "\n",
        "print(\"\\nMyGradientBoosting + top-20 жанров/студий \")\n",
        "print(\"Accuracy:\", accuracy_score(y3_test, y_pred_my_gb3))\n",
        "print(\"F1-score:\", f1_score(y3_test, y_pred_my_gb3))\n",
        "print(\"ROC-AUC:\", roc_auc_score(y3_test, y_proba_my_gb3))\n",
        "print(classification_report(y3_test, y_pred_my_gb3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sg7-fEDHXC-o",
        "outputId": "f9cbd714-fcfc-4962-a4ca-98d7774c0cfa"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лучшие параметры: {'clf__learning_rate': 0.2, 'clf__max_depth': 4, 'clf__n_estimators': 300}\n",
            "Лучший F1 на CV: 0.3773161705172974\n",
            "\n",
            "MyGradientBoosting + top-20 жанров/студий \n",
            "Accuracy: 0.7560165975103734\n",
            "F1-score: 0.3287671232876712\n",
            "ROC-AUC: 0.7019849214905429\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.93      0.85       903\n",
            "           1       0.53      0.24      0.33       302\n",
            "\n",
            "    accuracy                           0.76      1205\n",
            "   macro avg       0.66      0.58      0.59      1205\n",
            "weighted avg       0.72      0.76      0.72      1205\n",
            "\n"
          ]
        }
      ]
    }
  ]
}