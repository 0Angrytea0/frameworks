{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V5E1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1WjG47iKABi"
      },
      "outputs": [],
      "source": [
        "#KGAT_746a8c48819a19cbaf8ca0048244831b"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opendatasets\n",
        "!pip install pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggChAygRK_OQ",
        "outputId": "b78d2091-88fc-4272-a03f-c69245192547"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from opendatasets) (4.67.1)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (from opendatasets) (1.7.4.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from opendatasets) (8.3.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (6.3.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2025.11.12)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (3.4.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (3.11)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (6.33.2)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (0.5.1)\n",
            "Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.22\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Скачиваем датасеты"
      ],
      "metadata": {
        "id": "geiDPJvlLKtx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od\n",
        "od.download(\"https://www.kaggle.com/datasets/syahrulapriansyah2/myanimelist-2025\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRgJkoFwLECh",
        "outputId": "fd6d1711-6406-40dc-b997-b7d510a6c480"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: angrytea\n",
            "Your Kaggle Key: ··········\n",
            "Dataset URL: https://www.kaggle.com/datasets/syahrulapriansyah2/myanimelist-2025\n",
            "Downloading myanimelist-2025.zip to ./myanimelist-2025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.57M/9.57M [00:00<00:00, 1.93GB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Библиотеки"
      ],
      "metadata": {
        "id": "-0lcrD13LIgU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, classification_report\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin"
      ],
      "metadata": {
        "id": "scaL4WFQLIPL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Открываем датасет  \n",
        "Удаляем строки, не имеющие в Members значения  \n",
        "Задаем условие успешности: тайтл успешный, если у него 75% и больше зрителей: 1 - аниме успешное (собрало много просмотров) 0 - не успешное  \n",
        "Для признаков возьмем Source, Type, Released_Season, Episodes, Genres, Studios, Demographic  \n",
        "Пропуски по эпизодам заменяем медианой, по категориальным признакам на Unknown, жанрам и студиям поставим пустые строки  \n",
        "Создаем список жанров  \n",
        "Ищем самые популярные жанры и делаем для них колонки  \n",
        "Список студий делаем  \n",
        "Ищем популярные студии, не учитывая 'add some'  \n",
        "Задаем колонки  \n",
        "Собираем матрицу X из фич и назначаем целевую переменную успешности y  \n",
        "Делим данные на train и test  \n",
        "Числовые и бинарные признаки будем масштабировать, а для категориальных используем one-hot encoding  "
      ],
      "metadata": {
        "id": "pqb3nrSCLMKJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option(\"display.max_columns\", None)\n",
        "df = pd.read_csv(\"myanimelist-2025/mal_anime.csv\")\n",
        "df[\"Members\"] = pd.to_numeric(df[\"Members\"], errors=\"coerce\")\n",
        "df = df.dropna(subset=[\"Members\"])\n",
        "th = df[\"Members\"].quantile(0.75)\n",
        "\n",
        "df[\"hit\"] = (df[\"Members\"] >= th).astype(int)\n",
        "df[\"Episodes\"] = pd.to_numeric(df[\"Episodes\"], errors=\"coerce\")\n",
        "m_episodes = df[\"Episodes\"].median()\n",
        "df[\"Episodes\"] = df[\"Episodes\"].fillna(m_episodes)\n",
        "\n",
        "for col in [\"Source\", \"Type\", \"Released_Season\", \"Demographic\"]:\n",
        "    df[col] = df[col].fillna(\"Unknown\")\n",
        "\n",
        "for col in [\"Genres\", \"Studios\"]: df[col] = df[col].fillna(\"\")\n",
        "\n",
        "df[\"Genres_l\"] = df[\"Genres\"].apply(lambda x: [i.strip() for i in str(x).split(\",\") if i.strip() != \"\"])\n",
        "genre_count = Counter()\n",
        "\n",
        "for g in df[\"Genres_l\"]:\n",
        "    genre_count.update(g)\n",
        "\n",
        "top_g = [i for i, _ in genre_count.most_common(10)]\n",
        "\n",
        "for g in top_g:\n",
        "    col_name = f\"genre_{g}\"\n",
        "    df[col_name] = df[\"Genres_l\"].apply(lambda lst: int(g in lst))\n",
        "\n",
        "g_cols = [f\"genre_{g}\" for g in top_g]\n",
        "df[\"Studios_l\"] = df[\"Studios\"].apply(lambda x: [i.strip() for i in str(x).split(\",\") if i.strip() != \"\"])\n",
        "\n",
        "studio_count = Counter()\n",
        "for s in df[\"Studios_l\"]:\n",
        "  for st in s:\n",
        "    clean_s = st.strip()\n",
        "    if \"add some\" in clean_s.lower(): continue\n",
        "    studio_count[clean_s] += 1\n",
        "\n",
        "top_s = [i for i, _ in studio_count.most_common(10)]\n",
        "for s in top_s:\n",
        "    col_name = f\"studio_{s}\"\n",
        "    df[col_name] = df[\"Studios_l\"].apply(lambda lst: int(s in lst))\n",
        "\n",
        "studio_cols = [f\"studio_{s}\" for s in top_s]\n",
        "\n",
        "num = [\"Episodes\"] + g_cols + studio_cols\n",
        "categ = [\"Source\", \"Type\", \"Released_Season\", \"Demographic\"]\n",
        "feature = num + categ\n",
        "\n",
        "X = df[feature]\n",
        "y = df[\"hit\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42,stratify=y)\n",
        "pred = ColumnTransformer(transformers=[\n",
        "    (\"num\", StandardScaler(),num),\n",
        "    (\"categ\", OneHotEncoder(handle_unknown=\"ignore\"), categ)\n",
        "])"
      ],
      "metadata": {
        "id": "wzcVcqOcLWkM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Строим базовый RandomForestClassifier с типичными настройками (100 деревьев, критерий gini, без учета дисбаланса классов), обучаю его на тренировочной выборке"
      ],
      "metadata": {
        "id": "NvAzn82gLZz0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cлучайный лес даёт довольно высокую общую точность (0.74) и неплохой ROC-AUC (0.71), но F1 по классу «hit» остаётся низким (0.35). Модель хорошо распознаёт неуспешные тайтлы (класс 0: precision ≈ 0.79, recall ≈ 0.89) и сильно перекошена в их сторону, при этом часто «промахивается» по успешным аниме (класс 1: recall всего 0.28). То есть базовая конфигурация леса по сути ведёт себя как ещё один консервативный фильтр, который мало рискует предсказывать «hit»"
      ],
      "metadata": {
        "id": "Hl6IbO_1b5Oi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_base = Pipeline(steps=[\n",
        "    (\"pred\", pred),\n",
        "    (\"clf\", RandomForestClassifier(\n",
        "        n_estimators=100,\n",
        "        criterion=\"gini\",\n",
        "        max_depth=None,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    ))\n",
        "])\n",
        "\n",
        "rf_base.fit(X_train, y_train)\n",
        "\n",
        "y_pred_base = rf_base.predict(X_test)\n",
        "y_proba_base = rf_base.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"Бейзлайн\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_base))\n",
        "print(\"F1-score:\", f1_score(y_test, y_pred_base))\n",
        "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba_base))\n",
        "print(classification_report(y_test, y_pred_base))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHg179i-LfJc",
        "outputId": "70287efa-1402-4169-8d29-b56b08b60847"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Бейзлайн\n",
            "Accuracy: 0.7385892116182573\n",
            "F1-score: 0.3531827515400411\n",
            "ROC-AUC: 0.7065466106356295\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.89      0.84       903\n",
            "           1       0.46      0.28      0.35       302\n",
            "\n",
            "    accuracy                           0.74      1205\n",
            "   macro avg       0.63      0.59      0.59      1205\n",
            "weighted avg       0.71      0.74      0.72      1205\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Первая гипотеза  \n",
        "В сетку включаю число деревьев, максимальную глубину, ограничение на размер узлов и стратегию выбора признаков, а также class_weight (None/balanced). Подбираю параметры через GridSearchCV по F1-метрике"
      ],
      "metadata": {
        "id": "5uFhgQ14LmZF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "F1 по классу hit заметно растёт (с 0.35 до 0.49) и ROC-AUC тоже улучшается (0.73 против 0.71), но за это мы платим падением общей точности до 0.67. То есть модель начинает активнее ловить редкий класс (recall для hit вырастает до 0.63), но начинает чаще ошибаться по неуспешным тайтлам. Такой режим более полезен, если важнее не пропускать потенциальные «хиты», чем поддерживать максимальную accuracy"
      ],
      "metadata": {
        "id": "Oz549bSYcCi5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid_rf_1 = {\n",
        "    \"clf__n_estimators\": [100, 300],\n",
        "    \"clf__max_depth\": [None, 10, 20],\n",
        "    \"clf__min_samples_split\": [2, 10, 20],\n",
        "    \"clf__min_samples_leaf\": [1, 2, 5],\n",
        "    \"clf__max_features\": [\"sqrt\", \"log2\"],\n",
        "    \"clf__class_weight\": [None, \"balanced\"],\n",
        "}\n",
        "\n",
        "rf_clf_1 = Pipeline(steps=[\n",
        "    (\"pred\", pred),\n",
        "    (\"clf\", RandomForestClassifier(\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    ))\n",
        "])\n",
        "\n",
        "grid_rf_1 = GridSearchCV(\n",
        "    estimator=rf_clf_1,\n",
        "    param_grid=param_grid_rf_1,\n",
        "    scoring=\"f1\",\n",
        "    cv=3,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid_rf_1.fit(X_train, y_train)\n",
        "\n",
        "print(\"Лучшие параметры:\", grid_rf_1.best_params_)\n",
        "print(\"Лучший F1 на CV:\", grid_rf_1.best_score_)\n",
        "\n",
        "best_rf_1 = grid_rf_1.best_estimator_\n",
        "y_pred_rf_1 = best_rf_1.predict(X_test)\n",
        "y_proba_rf_1 = best_rf_1.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"\\nГипотеза 1\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf_1))\n",
        "print(\"F1-score:\", f1_score(y_test, y_pred_rf_1))\n",
        "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba_rf_1))\n",
        "print(classification_report(y_test, y_pred_rf_1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEzZNpNWLmN9",
        "outputId": "0f7f3f93-4ec5-49f5-dc6a-754e20b87f66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лучшие параметры: {'clf__class_weight': 'balanced', 'clf__max_depth': 10, 'clf__max_features': 'log2', 'clf__min_samples_leaf': 2, 'clf__min_samples_split': 20, 'clf__n_estimators': 300}\n",
            "Лучший F1 на CV: 0.488091410462309\n",
            "\n",
            "Гипотеза 1\n",
            "Accuracy: 0.674688796680498\n",
            "F1-score: 0.4909090909090909\n",
            "ROC-AUC: 0.7296869155794151\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.69      0.76       903\n",
            "           1       0.40      0.63      0.49       302\n",
            "\n",
            "    accuracy                           0.67      1205\n",
            "   macro avg       0.63      0.66      0.63      1205\n",
            "weighted avg       0.74      0.67      0.69      1205\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вторая гипотеза"
      ],
      "metadata": {
        "id": "c0zODZMwMG4o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Небольшой, но устойчивый прирост качества: F1 поднимается до 0.51, ROC-AUC — до 0.74, а accuracy остаётся на уровне 0.69. Распределение по классам становится более сбалансированным: модель немного улучшает и способность находить успешные тайтлы (recall 0.64), и общее качество. Логарифмирование длины сериала помогает лесу лучше учитывать различия между короткими и длинными тайтлами, не давая одному признаку доминировать"
      ],
      "metadata": {
        "id": "CW0rQ_-scMwX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df.copy()\n",
        "df2[\"log_Episodes\"] = np.log1p(df2[\"Episodes\"])\n",
        "\n",
        "num2 = [\"log_Episodes\"] + g_cols + studio_cols\n",
        "categ = [\"Source\", \"Type\", \"Released_Season\", \"Demographic\"]\n",
        "feature2 = num2 + categ\n",
        "\n",
        "X2 = df2[feature2]\n",
        "y2 = df2[\"hit\"]\n",
        "\n",
        "X2_train, X2_test, y2_train, y2_test = train_test_split(\n",
        "    X2, y2,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y2\n",
        ")\n",
        "\n",
        "pred2 = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num2\", StandardScaler(), num2),\n",
        "        (\"categ\", OneHotEncoder(handle_unknown=\"ignore\"), categ),\n",
        "    ]\n",
        ")\n",
        "\n",
        "rf_clf_2 = Pipeline(steps=[\n",
        "    (\"pred\", pred2),\n",
        "    (\"clf\", RandomForestClassifier(\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    ))\n",
        "])\n",
        "\n",
        "grid_rf_2 = GridSearchCV(\n",
        "    estimator=rf_clf_2,\n",
        "    param_grid=param_grid_rf_1,\n",
        "    scoring=\"f1\",\n",
        "    cv=3,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid_rf_2.fit(X2_train, y2_train)\n",
        "\n",
        "print(\"Лучшие параметры:\", grid_rf_2.best_params_)\n",
        "print(\"Лучший F1 на CV:\", grid_rf_2.best_score_)\n",
        "\n",
        "best_rf_2 = grid_rf_2.best_estimator_\n",
        "y_pred_rf_2 = best_rf_2.predict(X2_test)\n",
        "y_proba_rf_2 = best_rf_2.predict_proba(X2_test)[:, 1]\n",
        "\n",
        "print(\"\\nRandomForest + log(Episodes)\")\n",
        "print(\"Accuracy:\", accuracy_score(y2_test, y_pred_rf_2))\n",
        "print(\"F1-score:\", f1_score(y2_test, y_pred_rf_2))\n",
        "print(\"ROC-AUC:\", roc_auc_score(y2_test, y_proba_rf_2))\n",
        "print(classification_report(y2_test, y_pred_rf_2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ud7mZBklMID5",
        "outputId": "b58d2a0d-f9b1-43b4-80d6-4ba800e8cfad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лучшие параметры: {'clf__class_weight': 'balanced', 'clf__max_depth': 20, 'clf__max_features': 'log2', 'clf__min_samples_leaf': 5, 'clf__min_samples_split': 20, 'clf__n_estimators': 300}\n",
            "Лучший F1 на CV: 0.4885597072008033\n",
            "\n",
            "RandomForest + log(Episodes)\n",
            "Accuracy: 0.6879668049792531\n",
            "F1-score: 0.5078534031413613\n",
            "ROC-AUC: 0.736859475039053\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.70      0.77       903\n",
            "           1       0.42      0.64      0.51       302\n",
            "\n",
            "    accuracy                           0.69      1205\n",
            "   macro avg       0.64      0.67      0.64      1205\n",
            "weighted avg       0.75      0.69      0.71      1205\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Третья гипотеза"
      ],
      "metadata": {
        "id": "57ueK-6fMOt0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Качество в целом остаётся на уровне гипотезы 1: F1 ≈ 0.485, ROC-AUC ≈ 0.73, accuracy ≈ 0.67. Модель по-прежнему лучше бейзлайна по F1, но чуть уступает конфигурации с логарифмом эпизодов. То есть агрессивное упрощение многомерных жанровых/студийных признаков до top-20 само по себе не даёт дополнительного выигрыша по сравнению с уже настроенным лесом; ключевой вклад в улучшение качества здесь делает балансировка классов и тюнинг параметров, а не срезание «хвоста» по жанрам и студиям"
      ],
      "metadata": {
        "id": "5veWxNPgcXTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_g20 = [g for g, _ in genre_count.most_common(20)]\n",
        "for g in top_g20:\n",
        "    col_name = f\"genre_{g}\"\n",
        "    if col_name not in df.columns:\n",
        "        df[col_name] = df[\"Genres_l\"].apply(lambda lst: int(g in lst))\n",
        "g_cols20 = [f\"genre_{g}\" for g in top_g20]\n",
        "\n",
        "top_s20 = [s for s, _ in studio_count.most_common(20)]\n",
        "for s in top_s20:\n",
        "    col_name = f\"studio_{s}\"\n",
        "    if col_name not in df.columns:\n",
        "        df[col_name] = df[\"Studios_l\"].apply(lambda lst: int(s in lst))\n",
        "studio_cols20 = [f\"studio_{s}\" for s in top_s20]\n",
        "\n",
        "num3 = [\"Episodes\"] + g_cols20 + studio_cols20\n",
        "categ3 = [\"Source\", \"Type\", \"Released_Season\", \"Demographic\"]\n",
        "feature3 = num3 + categ3\n",
        "\n",
        "X3 = df[feature3]\n",
        "y3 = df[\"hit\"]\n",
        "\n",
        "X3_train, X3_test, y3_train, y3_test = train_test_split(\n",
        "    X3, y3,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y3\n",
        ")\n",
        "\n",
        "pred3 = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", StandardScaler(), num3),\n",
        "        (\"categ\", OneHotEncoder(handle_unknown=\"ignore\"), categ3),\n",
        "    ]\n",
        ")\n",
        "\n",
        "rf_clf_3 = Pipeline(steps=[\n",
        "    (\"pred\", pred3),\n",
        "    (\"clf\", RandomForestClassifier(\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    ))\n",
        "])\n",
        "\n",
        "grid_rf_3 = GridSearchCV(\n",
        "    estimator=rf_clf_3,\n",
        "    param_grid=param_grid_rf_1,\n",
        "    scoring=\"f1\",\n",
        "    cv=3,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid_rf_3.fit(X3_train, y3_train)\n",
        "\n",
        "print(\"Лучшие параметры:\", grid_rf_3.best_params_)\n",
        "print(\"Лучший F1 на CV:\", grid_rf_3.best_score_)\n",
        "\n",
        "best_rf_3 = grid_rf_3.best_estimator_\n",
        "y_pred_rf_3 = best_rf_3.predict(X3_test)\n",
        "y_proba_rf_3 = best_rf_3.predict_proba(X3_test)[:, 1]\n",
        "\n",
        "print(\"\\nRandomForest + top-20 жанров/студий\")\n",
        "print(\"Accuracy:\", accuracy_score(y3_test, y_pred_rf_3))\n",
        "print(\"F1-score:\", f1_score(y3_test, y_pred_rf_3))\n",
        "print(\"ROC-AUC:\", roc_auc_score(y3_test, y_proba_rf_3))\n",
        "print(classification_report(y3_test, y_pred_rf_3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ODukTpAMQCb",
        "outputId": "1c903125-6fd4-465d-bf38-43ad9bf571c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лучшие параметры: {'clf__class_weight': 'balanced', 'clf__max_depth': 10, 'clf__max_features': 'log2', 'clf__min_samples_leaf': 2, 'clf__min_samples_split': 20, 'clf__n_estimators': 300}\n",
            "Лучший F1 на CV: 0.49006025697151706\n",
            "\n",
            "RandomForest + top-20 жанров/студий\n",
            "Accuracy: 0.6721991701244814\n",
            "F1-score: 0.485006518904824\n",
            "ROC-AUC: 0.7277085946037125\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.69      0.76       903\n",
            "           1       0.40      0.62      0.49       302\n",
            "\n",
            "    accuracy                           0.67      1205\n",
            "   macro avg       0.62      0.65      0.62      1205\n",
            "weighted avg       0.73      0.67      0.69      1205\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Собственная реализация"
      ],
      "metadata": {
        "id": "RknOFAwzMzhS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDecisionTreeClassifier(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(\n",
        "        self,\n",
        "        max_depth=None,\n",
        "        min_samples_split=2,\n",
        "        min_samples_leaf=1,\n",
        "        criterion=\"gini\",\n",
        "        random_state=None\n",
        "    ):\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.min_samples_leaf = min_samples_leaf\n",
        "        self.criterion = criterion\n",
        "        self.random_state = random_state\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        X = np.asarray(X)\n",
        "        y = np.asarray(y)\n",
        "\n",
        "        self.classes_ = np.unique(y)\n",
        "        self.n_classes_ = self.classes_.shape[0]\n",
        "        if self.n_classes_ != 2:\n",
        "            raise ValueError(\"MyDecisionTreeClassifier сейчас поддерживает только бинарную классификацию\")\n",
        "\n",
        "        if self.criterion != \"gini\":\n",
        "            raise ValueError(\"В данной реализации поддерживается только criterion='gini'\")\n",
        "\n",
        "        rng = np.random.RandomState(self.random_state)\n",
        "\n",
        "        self.n_features_ = X.shape[1]\n",
        "        self.tree_ = self._build_tree(X, y, depth=0, rng=rng)\n",
        "        return self\n",
        "\n",
        "    def _gini(self, y):\n",
        "        m = y.shape[0]\n",
        "        if m == 0:\n",
        "            return 0.0\n",
        "        _, counts = np.unique(y, return_counts=True)\n",
        "        p = counts / m\n",
        "        return 1.0 - np.sum(p ** 2)\n",
        "\n",
        "    def _best_split(self, X, y):\n",
        "        m, n = X.shape\n",
        "        if m < self.min_samples_split:\n",
        "            return None, None\n",
        "\n",
        "        best_gini = None\n",
        "        best_feature = None\n",
        "        best_threshold = None\n",
        "\n",
        "        current_gini = self._gini(y)\n",
        "\n",
        "        for feature_idx in range(n):\n",
        "            x_col = X[:, feature_idx]\n",
        "            thresholds = np.unique(x_col)\n",
        "            if thresholds.shape[0] == 1:\n",
        "                continue\n",
        "\n",
        "            for t in thresholds:\n",
        "                left_mask = x_col <= t\n",
        "                right_mask = x_col > t\n",
        "\n",
        "                n_left = np.sum(left_mask)\n",
        "                n_right = np.sum(right_mask)\n",
        "\n",
        "                if n_left < self.min_samples_leaf or n_right < self.min_samples_leaf:\n",
        "                    continue\n",
        "\n",
        "                g_left = self._gini(y[left_mask])\n",
        "                g_right = self._gini(y[right_mask])\n",
        "\n",
        "                g_split = (n_left * g_left + n_right * g_right) / m\n",
        "\n",
        "                if best_gini is None or g_split < best_gini:\n",
        "                    best_gini = g_split\n",
        "                    best_feature = feature_idx\n",
        "                    best_threshold = t\n",
        "\n",
        "        if best_gini is None or best_gini >= current_gini:\n",
        "            return None, None\n",
        "\n",
        "        return best_feature, best_threshold\n",
        "\n",
        "    def _build_tree(self, X, y, depth, rng):\n",
        "        node = {}\n",
        "        num_samples = y.shape[0]\n",
        "        num_labels = np.unique(y).shape[0]\n",
        "\n",
        "        if num_labels == 1:\n",
        "            node[\"type\"] = \"leaf\"\n",
        "            node[\"class_counts\"] = self._class_counts(y)\n",
        "            return node\n",
        "\n",
        "        if self.max_depth is not None and depth >= self.max_depth:\n",
        "            node[\"type\"] = \"leaf\"\n",
        "            node[\"class_counts\"] = self._class_counts(y)\n",
        "            return node\n",
        "\n",
        "        if num_samples < self.min_samples_split:\n",
        "            node[\"type\"] = \"leaf\"\n",
        "            node[\"class_counts\"] = self._class_counts(y)\n",
        "            return node\n",
        "\n",
        "        feature_idx, threshold = self._best_split(X, y)\n",
        "\n",
        "        if feature_idx is None:\n",
        "            node[\"type\"] = \"leaf\"\n",
        "            node[\"class_counts\"] = self._class_counts(y)\n",
        "            return node\n",
        "\n",
        "        left_mask = X[:, feature_idx] <= threshold\n",
        "        right_mask = X[:, feature_idx] > threshold\n",
        "\n",
        "        X_left, y_left = X[left_mask], y[left_mask]\n",
        "        X_right, y_right = X[right_mask], y[right_mask]\n",
        "\n",
        "        node[\"type\"] = \"internal\"\n",
        "        node[\"feature_idx\"] = feature_idx\n",
        "        node[\"threshold\"] = threshold\n",
        "        node[\"left\"] = self._build_tree(X_left, y_left, depth + 1, rng)\n",
        "        node[\"right\"] = self._build_tree(X_right, y_right, depth + 1, rng)\n",
        "\n",
        "        return node\n",
        "\n",
        "    def _class_counts(self, y):\n",
        "        counts = np.zeros(self.n_classes_, dtype=float)\n",
        "        for idx, c in enumerate(self.classes_):\n",
        "            counts[idx] = np.sum(y == c)\n",
        "        return counts\n",
        "\n",
        "    def _predict_one_proba(self, x, node):\n",
        "        if node[\"type\"] == \"leaf\":\n",
        "            counts = node[\"class_counts\"]\n",
        "            total = np.sum(counts)\n",
        "            if total == 0:\n",
        "                return np.ones(self.n_classes_) / self.n_classes_\n",
        "            return counts / total\n",
        "\n",
        "        if x[node[\"feature_idx\"]] <= node[\"threshold\"]:\n",
        "            return self._predict_one_proba(x, node[\"left\"])\n",
        "        else:\n",
        "            return self._predict_one_proba(x, node[\"right\"])\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        X = np.asarray(X)\n",
        "        n_samples = X.shape[0]\n",
        "        proba = np.zeros((n_samples, self.n_classes_), dtype=float)\n",
        "        for i in range(n_samples):\n",
        "            proba[i] = self._predict_one_proba(X[i], self.tree_)\n",
        "        return proba\n",
        "\n",
        "    def predict(self, X):\n",
        "        proba = self.predict_proba(X)\n",
        "        idx = np.argmax(proba, axis=1)\n",
        "        return self.classes_[idx]\n",
        "\n",
        "\n",
        "class MyRandomForestClassifier(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(\n",
        "        self,\n",
        "        n_estimators=100,\n",
        "        max_depth=None,\n",
        "        min_samples_split=2,\n",
        "        min_samples_leaf=1,\n",
        "        max_features=\"sqrt\",\n",
        "        bootstrap=True,\n",
        "        criterion=\"gini\",\n",
        "        random_state=None\n",
        "    ):\n",
        "        self.n_estimators = n_estimators\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.min_samples_leaf = min_samples_leaf\n",
        "        self.max_features = max_features\n",
        "        self.bootstrap = bootstrap\n",
        "        self.criterion = criterion\n",
        "        self.random_state = random_state\n",
        "\n",
        "    def _get_n_features_subspace(self, n_features):\n",
        "        if isinstance(self.max_features, int):\n",
        "            return max(1, min(self.max_features, n_features))\n",
        "        if self.max_features in [\"sqrt\", None, \"auto\"]:\n",
        "            return max(1, int(np.sqrt(n_features)))\n",
        "        if self.max_features == \"log2\":\n",
        "            return max(1, int(np.log2(n_features)))\n",
        "        return n_features\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        X = np.asarray(X)\n",
        "        y = np.asarray(y)\n",
        "\n",
        "        self.classes_ = np.unique(y)\n",
        "        n_samples, n_features = X.shape\n",
        "        n_feats_sub = self._get_n_features_subspace(n_features)\n",
        "\n",
        "        rng = np.random.RandomState(self.random_state)\n",
        "\n",
        "        self.trees_ = []\n",
        "        self.features_idx_ = []\n",
        "\n",
        "        for i in range(self.n_estimators):\n",
        "            if self.bootstrap:\n",
        "                sample_idx = rng.randint(0, n_samples, size=n_samples)\n",
        "            else:\n",
        "                sample_idx = np.arange(n_samples)\n",
        "\n",
        "            feat_idx = rng.choice(n_features, size=n_feats_sub, replace=False)\n",
        "\n",
        "            X_boot = X[sample_idx][:, feat_idx]\n",
        "            y_boot = y[sample_idx]\n",
        "\n",
        "            tree = MyDecisionTreeClassifier(\n",
        "                max_depth=self.max_depth,\n",
        "                min_samples_split=self.min_samples_split,\n",
        "                min_samples_leaf=self.min_samples_leaf,\n",
        "                criterion=self.criterion,\n",
        "                random_state=None if self.random_state is None else self.random_state + i\n",
        "            )\n",
        "            tree.fit(X_boot, y_boot)\n",
        "\n",
        "            self.trees_.append(tree)\n",
        "            self.features_idx_.append(feat_idx)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        X = np.asarray(X)\n",
        "        n_samples = X.shape[0]\n",
        "        n_classes = len(self.classes_)\n",
        "\n",
        "        proba_sum = np.zeros((n_samples, n_classes), dtype=float)\n",
        "\n",
        "        for tree, feat_idx in zip(self.trees_, self.features_idx_):\n",
        "            X_sub = X[:, feat_idx]\n",
        "            proba_sum += tree.predict_proba(X_sub)\n",
        "\n",
        "        proba_avg = proba_sum / len(self.trees_)\n",
        "        return proba_avg\n",
        "\n",
        "    def predict(self, X):\n",
        "        proba = self.predict_proba(X)\n",
        "        idx = np.argmax(proba, axis=1)\n",
        "        return self.classes_[idx]"
      ],
      "metadata": {
        "id": "P2-O3NwTM1xZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Бейзлайн"
      ],
      "metadata": {
        "id": "kqfLQWRUM_eo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Из отчёта по классам видно, что модель предсказывает только класс 0 (неуспешное аниме). По классу 0 точность и полнота очень высокие, по классу 1 полнота равна 0, F1 тоже 0 — модель вообще не находит «хиты»  \n",
        "Такая картина говорит о том, что моя реализация случайного леса в текущем виде деградировала до константного классификатора, который выбирает только majority class. При этом ROC-AUC ≈ 0.71 намекает, что какие-то различия между объектами модель всё же ловит (по вероятностям), но при пороге 0.5 она всегда уходит в класс 0  \n",
        "Подбор гиперпараметров в гипотезе 1 не улучшил ситуацию, потому что при F1=0 для всех комбинаций GridSearchCV просто вернул первый же набор параметров. Для реального применения такую модель использовать нельзя — её нужно дорабатывать: добавлять учёт несбалансированности классов, настраивать порог, либо внимательно проверять логику голосования и предсказаний в реализации леса\n"
      ],
      "metadata": {
        "id": "0DuMmzPMofQX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_rf_base = Pipeline(steps=[\n",
        "    (\"pred\", pred),\n",
        "    (\"clf\", MyRandomForestClassifier(\n",
        "        n_estimators=100,\n",
        "        max_depth=None,\n",
        "        min_samples_split=2,\n",
        "        min_samples_leaf=1,\n",
        "        max_features=\"sqrt\",\n",
        "        bootstrap=True,\n",
        "        criterion=\"gini\",\n",
        "        random_state=42\n",
        "    ))\n",
        "])\n",
        "\n",
        "my_rf_base.fit(X_train, y_train)\n",
        "\n",
        "y_pred_my_base = my_rf_base.predict(X_test)\n",
        "y_proba_my_base = my_rf_base.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"Бейзлайн\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_my_base))\n",
        "print(\"F1-score:\", f1_score(y_test, y_pred_my_base))\n",
        "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba_my_base))\n",
        "print(classification_report(y_test, y_pred_my_base))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzyjhwFWM_OT",
        "outputId": "a5fdb753-79ed-4acd-ec06-06338b0b9297"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Бейзлайн\n",
            "Accuracy: 0.7493775933609959\n",
            "F1-score: 0.0\n",
            "ROC-AUC: 0.7149054292901513\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      1.00      0.86       903\n",
            "           1       0.00      0.00      0.00       302\n",
            "\n",
            "    accuracy                           0.75      1205\n",
            "   macro avg       0.37      0.50      0.43      1205\n",
            "weighted avg       0.56      0.75      0.64      1205\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Гипотеза 1"
      ],
      "metadata": {
        "id": "RM8TjyI-NFfM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Из отчёта видно, что модель по-прежнему предсказывает только класс 0 и полностью игнорирует класс 1 (ни одной верной «популярной» аниме), поэтому F1 по целевому классу равен нулю. Формально гиперпараметры подобраны, но из-за особенностей моей реализации леса и дисбаланса классов подбор параметров не меняет поведение модели: она остаётся по сути константным классификатором"
      ],
      "metadata": {
        "id": "lHFgCNqDo3Aj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid_my_rf_1 = {\n",
        "    \"clf__n_estimators\": [100, 300],\n",
        "    \"clf__max_depth\": [None, 10, 20],\n",
        "    \"clf__min_samples_split\": [2, 10, 20],\n",
        "    \"clf__min_samples_leaf\": [1, 2, 5],\n",
        "    \"clf__max_features\": [\"sqrt\", \"log2\"],\n",
        "}\n",
        "\n",
        "my_rf_clf_1 = Pipeline(steps=[\n",
        "    (\"pred\", pred),\n",
        "    (\"clf\", MyRandomForestClassifier(\n",
        "        bootstrap=True,\n",
        "        criterion=\"gini\",\n",
        "        random_state=42\n",
        "    ))\n",
        "])\n",
        "\n",
        "grid_my_rf_1 = GridSearchCV(\n",
        "    estimator=my_rf_clf_1,\n",
        "    param_grid=param_grid_my_rf_1,\n",
        "    scoring=\"f1\",\n",
        "    cv=3,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid_my_rf_1.fit(X_train, y_train)\n",
        "\n",
        "print(\"Лучшие параметры:\", grid_my_rf_1.best_params_)\n",
        "print(\"Лучший F1 на CV:\", grid_my_rf_1.best_score_)\n",
        "\n",
        "best_my_rf_1 = grid_my_rf_1.best_estimator_\n",
        "y_pred_my_rf_1 = best_my_rf_1.predict(X_test)\n",
        "y_proba_my_rf_1 = best_my_rf_1.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"\\nГипотеза 1\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_my_rf_1))\n",
        "print(\"F1-score:\", f1_score(y_test, y_pred_my_rf_1))\n",
        "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba_my_rf_1))\n",
        "print(classification_report(y_test, y_pred_my_rf_1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXtyEQd-NG5q",
        "outputId": "83ab7c7b-77d9-4f42-fe97-c4a92cc09cab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лучшие параметры: {'clf__max_depth': None, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 2, 'clf__n_estimators': 100}\n",
            "Лучший F1 на CV: 0.0\n",
            "\n",
            "Гипотеза 1\n",
            "Accuracy: 0.7493775933609959\n",
            "F1-score: 0.0\n",
            "ROC-AUC: 0.7149054292901513\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      1.00      0.86       903\n",
            "           1       0.00      0.00      0.00       302\n",
            "\n",
            "    accuracy                           0.75      1205\n",
            "   macro avg       0.37      0.50      0.43      1205\n",
            "weighted avg       0.56      0.75      0.64      1205\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Гипотеза 2"
      ],
      "metadata": {
        "id": "cqOVAQE9NP_C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Однако GridSearchCV снова находит лучший F1 = 0.0, а итоговые метрики на тесте полностью совпадают с бейзлайном: accuracy ≈ 0.75, F1 = 0.0, ROC-AUC ≈ 0.71. Модель по-прежнему всегда предсказывает класс 0 и вообще не находит успешные тайтлы (класс 1), из-за чего F1 по целевому классу остаётся нулевым. То есть логарифмирование признака в рамках моей реализации случайного леса ситуацию не исправило"
      ],
      "metadata": {
        "id": "Q3CCr0BtpnRB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid_my_rf_1 = {\n",
        "    \"clf__n_estimators\": [100, 300],\n",
        "    \"clf__max_depth\": [None, 10, 20],\n",
        "    \"clf__min_samples_split\": [2, 10, 20],\n",
        "    \"clf__min_samples_leaf\": [1, 2, 5],\n",
        "    \"clf__max_features\": [\"sqrt\", \"log2\"],\n",
        "}\n",
        "\n",
        "my_rf_clf_1 = Pipeline(steps=[\n",
        "    (\"pred\", pred),\n",
        "    (\"clf\", MyRandomForestClassifier(\n",
        "        bootstrap=True,\n",
        "        criterion=\"gini\",\n",
        "        random_state=42\n",
        "    ))\n",
        "])\n",
        "df2 = df.copy()\n",
        "df2[\"log_Episodes\"] = np.log1p(df2[\"Episodes\"])\n",
        "\n",
        "num2 = [\"log_Episodes\"] + g_cols + studio_cols\n",
        "categ = [\"Source\", \"Type\", \"Released_Season\", \"Demographic\"]\n",
        "feature2 = num2 + categ\n",
        "\n",
        "X2 = df2[feature2]\n",
        "y2 = df2[\"hit\"]\n",
        "\n",
        "X2_train, X2_test, y2_train, y2_test = train_test_split(\n",
        "    X2, y2,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y2\n",
        ")\n",
        "\n",
        "pred2 = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num2\", StandardScaler(), num2),\n",
        "        (\"categ\", OneHotEncoder(handle_unknown=\"ignore\"), categ),\n",
        "    ]\n",
        ")\n",
        "\n",
        "my_rf_clf_2 = Pipeline(steps=[\n",
        "    (\"pred\", pred2),\n",
        "    (\"clf\", MyRandomForestClassifier(\n",
        "        bootstrap=True,\n",
        "        criterion=\"gini\",\n",
        "        random_state=42\n",
        "    ))\n",
        "])\n",
        "\n",
        "grid_my_rf_2 = GridSearchCV(\n",
        "    estimator=my_rf_clf_2,\n",
        "    param_grid=param_grid_my_rf_1,\n",
        "    scoring=\"f1\",\n",
        "    cv=3,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid_my_rf_2.fit(X2_train, y2_train)\n",
        "\n",
        "print(\"Лучшие параметры:\", grid_my_rf_2.best_params_)\n",
        "print(\"Лучший F1 на CV:\", grid_my_rf_2.best_score_)\n",
        "\n",
        "best_my_rf_2 = grid_my_rf_2.best_estimator_\n",
        "y_pred_my_rf_2 = best_my_rf_2.predict(X2_test)\n",
        "y_proba_my_rf_2 = best_my_rf_2.predict_proba(X2_test)[:, 1]\n",
        "\n",
        "print(\"\\nMyRandomForestClassifier + log(Episodes)\")\n",
        "print(\"Accuracy:\", accuracy_score(y2_test, y_pred_my_rf_2))\n",
        "print(\"F1-score:\", f1_score(y2_test, y_pred_my_rf_2))\n",
        "print(\"ROC-AUC:\", roc_auc_score(y2_test, y_proba_my_rf_2))\n",
        "print(classification_report(y2_test, y_pred_my_rf_2))\n"
      ],
      "metadata": {
        "id": "HCy1gyTsNQ4R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2062b0c6-d75c-44aa-f51d-26e50e222095"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лучшие параметры: {'clf__max_depth': None, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 2, 'clf__n_estimators': 100}\n",
            "Лучший F1 на CV: 0.0\n",
            "\n",
            "MyRandomForestClassifier + log(Episodes)\n",
            "Accuracy: 0.7493775933609959\n",
            "F1-score: 0.0\n",
            "ROC-AUC: 0.7149054292901513\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      1.00      0.86       903\n",
            "           1       0.00      0.00      0.00       302\n",
            "\n",
            "    accuracy                           0.75      1205\n",
            "   macro avg       0.37      0.50      0.43      1205\n",
            "weighted avg       0.56      0.75      0.64      1205\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Гипотеза 3"
      ],
      "metadata": {
        "id": "Gr1-K3FENbhf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Результат снова тот же: лучший F1 на кросс-валидации равен 0.0, accuracy на тесте ≈ 0.75, F1 = 0.0, ROC-AUC ≈ 0.71. Модель по сути остаётся константным классификатором, который всегда выбирает класс 0, даже при более информативном наборе признаков. Это показывает, что проблема не в признаках, а именно в упрощённой реализации моего случайного леса, которая не справляется с дисбалансом классов и практически игнорирует редкий класс успешных аниме."
      ],
      "metadata": {
        "id": "GTi1JIOups7X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_g20 = [g for g, _ in genre_count.most_common(20)]\n",
        "for g in top_g20:\n",
        "    col_name = f\"genre_{g}\"\n",
        "    if col_name not in df.columns:\n",
        "        df[col_name] = df[\"Genres_l\"].apply(lambda lst: int(g in lst))\n",
        "g_cols20 = [f\"genre_{g}\" for g in top_g20]\n",
        "\n",
        "top_s20 = [s for s, _ in studio_count.most_common(20)]\n",
        "for s in top_s20:\n",
        "    col_name = f\"studio_{s}\"\n",
        "    if col_name not in df.columns:\n",
        "        df[col_name] = df[\"Studios_l\"].apply(lambda lst: int(s in lst))\n",
        "studio_cols20 = [f\"studio_{s}\" for s in top_s20]\n",
        "\n",
        "num3 = [\"Episodes\"] + g_cols20 + studio_cols20\n",
        "categ3 = [\"Source\", \"Type\", \"Released_Season\", \"Demographic\"]\n",
        "feature3 = num3 + categ3\n",
        "\n",
        "X3 = df[feature3]\n",
        "y3 = df[\"hit\"]\n",
        "\n",
        "X3_train, X3_test, y3_train, y3_test = train_test_split(\n",
        "    X3, y3,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y3\n",
        ")\n",
        "\n",
        "pred3 = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", StandardScaler(), num3),\n",
        "        (\"categ\", OneHotEncoder(handle_unknown=\"ignore\"), categ3),\n",
        "    ]\n",
        ")\n",
        "\n",
        "my_rf_clf_3 = Pipeline(steps=[\n",
        "    (\"pred\", pred3),\n",
        "    (\"clf\", MyRandomForestClassifier(\n",
        "        bootstrap=True,\n",
        "        criterion=\"gini\",\n",
        "        random_state=42\n",
        "    ))\n",
        "])\n",
        "\n",
        "grid_my_rf_3 = GridSearchCV(\n",
        "    estimator=my_rf_clf_3,\n",
        "    param_grid=param_grid_my_rf_1,\n",
        "    scoring=\"f1\",\n",
        "    cv=3,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid_my_rf_3.fit(X3_train, y3_train)\n",
        "\n",
        "print(\"Лучшие параметры:\", grid_my_rf_3.best_params_)\n",
        "print(\"Лучший F1 на CV:\", grid_my_rf_3.best_score_)\n",
        "\n",
        "best_my_rf_3 = grid_my_rf_3.best_estimator_\n",
        "y_pred_my_rf_3 = best_my_rf_3.predict(X3_test)\n",
        "y_proba_my_rf_3 = best_my_rf_3.predict_proba(X3_test)[:, 1]\n",
        "\n",
        "print(\"\\nMyRandomForestClassifier + top-20 жанров/студий\")\n",
        "print(\"Accuracy:\", accuracy_score(y3_test, y_pred_my_rf_3))\n",
        "print(\"F1-score:\", f1_score(y3_test, y_pred_my_rf_3))\n",
        "print(\"ROC-AUC:\", roc_auc_score(y3_test, y_proba_my_rf_3))\n",
        "print(classification_report(y3_test, y_pred_my_rf_3))\n"
      ],
      "metadata": {
        "id": "xP9LlFOqNeNw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c54a8407-a68b-4b0a-bdbf-fdd13be97d08"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лучшие параметры: {'clf__max_depth': None, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 2, 'clf__n_estimators': 100}\n",
            "Лучший F1 на CV: 0.0\n",
            "\n",
            "MyRandomForestClassifier + top-20 жанров/студий\n",
            "Accuracy: 0.7493775933609959\n",
            "F1-score: 0.0\n",
            "ROC-AUC: 0.7118196886023775\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      1.00      0.86       903\n",
            "           1       0.00      0.00      0.00       302\n",
            "\n",
            "    accuracy                           0.75      1205\n",
            "   macro avg       0.37      0.50      0.43      1205\n",
            "weighted avg       0.56      0.75      0.64      1205\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Библиотечный случайный лес показал, что при корректной настройке гиперпараметров и обработке дисбаланса классов можно существенно повысить качество модели. Бейзлайн давал F1 около 0.35, но после тюнинга и логарифмирования признаков F1 вырос до 0.5 при небольшом падении accuracy. Наилучшие результаты показала гипотеза с логарифмом количества эпизодов — модель стала увереннее находить «хиты», сохраняя общую устойчивость предсказаний   \n",
        "Собственная реализация случайного леса оказалась неудачной: во всех экспериментах accuracy ≈ 0.75, но F1 = 0. Модель предсказывает только класс 0 и полностью игнорирует редкий класс 1. Это говорит о том, что реализация не обрабатывает дисбаланс и недостаточно точно вычисляет разбиения. Следовательно, библиотечная версия значительно эффективнее и стабильнее для задачи классификации аниме"
      ],
      "metadata": {
        "id": "3YyeKxgsNn5H"
      }
    }
  ]
}